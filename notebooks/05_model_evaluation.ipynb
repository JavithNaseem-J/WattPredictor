{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "sys.path.append(os.path.join(os.getcwd(), \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from WattPredictor.utils.helpers import *\n",
    "from WattPredictor.utils.exception import *\n",
    "from WattPredictor.constants import *\n",
    "from WattPredictor import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelEvaluationConfig:\n",
    "    model_path: Path\n",
    "    x_transform: Path\n",
    "    y_transform: Path\n",
    "    metrics_path: Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class FeatureStoreConfig:\n",
    "    hopsworks_project_name: str\n",
    "    hopsworks_api_key: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config_filepath = CONFIG_PATH,\n",
    "                 params_filepath = PARAMS_PATH,\n",
    "                 schema_filepath = SCHEMA_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_evaluation_config(self) -> ModelEvaluationConfig:\n",
    "        config = self.config.model_evaluation\n",
    "\n",
    "        model_evaluation_config =  ModelEvaluationConfig(\n",
    "            model_path=Path(config.model_path),\n",
    "            x_transform=Path(config.X_transform),\n",
    "            y_transform=Path(config.y_transform),\n",
    "            metrics_path=Path(config.metrics_path)\n",
    "        )\n",
    "\n",
    "        return model_evaluation_config\n",
    "    \n",
    "    def get_feature_store_config(self) -> FeatureStoreConfig:\n",
    "\n",
    "        config = self.config.feature_store\n",
    "\n",
    "        feature_store_config = FeatureStoreConfig(\n",
    "                hopsworks_project_name=config.hopsworks_project_name,\n",
    "                hopsworks_api_key=os.environ['hopsworks_api_key'],\n",
    "        )\n",
    "\n",
    "        return feature_store_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from WattPredictor.utils.exception import CustomException\n",
    "from WattPredictor import logger\n",
    "\n",
    "class FeatureStore:\n",
    "    def __init__(self, config):\n",
    "        try:\n",
    "            self.config = config\n",
    "            self.connect()\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def connect(self):\n",
    "        try:\n",
    "            self.project = hopsworks.login(\n",
    "                project=self.config.hopsworks_project_name,\n",
    "                api_key_value=self.config.hopsworks_api_key\n",
    "            )\n",
    "            self.feature_store = self.project.get_feature_store()\n",
    "            self.dataset_api = self.project.get_dataset_api()\n",
    "            logger.info(f\"Connected to Hopsworks Feature Store: {self.config.hopsworks_project_name}\")\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def create_feature_group(self, name, df, primary_key, event_time, description):\n",
    "        try:\n",
    "            try:\n",
    "                fg = self.feature_store.get_feature_group(name=name, version=1)\n",
    "                logger.info(f\"Feature Group '{name}' already exists. Inserting data instead.\")\n",
    "                fg.insert(df)\n",
    "            except:\n",
    "                logger.info(f\"Feature Group '{name}' does not exist. Creating new one.\")\n",
    "                fg = self.feature_store.get_or_create_feature_group(\n",
    "                    name=name,\n",
    "                    version=1,\n",
    "                    primary_key=primary_key,\n",
    "                    event_time=event_time,\n",
    "                    description=description,\n",
    "                    online_enabled=False\n",
    "                )\n",
    "                fg.save(df)\n",
    "\n",
    "            logger.info(f\"Feature Group '{name}' created/updated successfully\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def create_feature_view(self, name: str, feature_group_name: str, features: list):\n",
    "        try:\n",
    "            fg = self.feature_store.get_feature_group(name=feature_group_name, version=1)\n",
    "            fv = self.feature_store.get_or_create_feature_view(\n",
    "                name=name,\n",
    "                version=1,\n",
    "                query=fg.select(features),\n",
    "                description=f\"Feature View for {name}\"\n",
    "            )\n",
    "            logger.info(f\"Feature View '{name}' created successfully\")\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def upload_file_safely(self, local_path: str, target_name: str):\n",
    "        \"\"\"\n",
    "        Upload file to Hopsworks dataset storage.\n",
    "        If it already exists, it will be overwritten.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.dataset_api.upload(\n",
    "                local_path,\n",
    "                f\"Resources/wattpredictor_artifacts/{target_name}\",\n",
    "                overwrite=True \n",
    "            )\n",
    "            logger.info(f\"Uploaded file to Feature Store: {target_name}\")\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "        \n",
    "    def download_file(self, remote_name: str, local_path: str = None):\n",
    "        \"\"\"\n",
    "        Download a file from Hopsworks dataset storage.\n",
    "\n",
    "        Args:\n",
    "            remote_name: filename in Hopsworks (inside wattpredictor_artifacts)\n",
    "            local_path: optional local path to save the file. If None, saves in current directory.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            target_path = f\"Resources/wattpredictor_artifacts/{remote_name}\"\n",
    "            if local_path is None:\n",
    "                local_path = remote_name\n",
    "\n",
    "            self.dataset_api.download(\n",
    "                target_path,\n",
    "                local_path=local_path,\n",
    "                overwrite=True\n",
    "            )\n",
    "            logger.info(f\"Downloaded file from Feature Store: {remote_name} to {local_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "\n",
    "    def delete_file(self, target_name: str):\n",
    "        \"\"\"\n",
    "        Delete file from Hopsworks dataset storage.\n",
    "        Only use this if you want to clean up files manually.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            full_path = f\"Resources/wattpredictor_artifacts/{target_name}\"\n",
    "            self.dataset_api.delete(full_path)\n",
    "            logger.warning(f\"Deleted file from Feature Store: {target_name}\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"File not found or already deleted: {target_name}\")\n",
    "            # Not raising exception here to allow safe cleanup\n",
    "\n",
    "    def get_training_data(self, feature_view_name: str):\n",
    "        try:\n",
    "            fv = self.feature_store.get_feature_view(name=feature_view_name, version=1)\n",
    "            X, y = fv.training_data()\n",
    "            logger.info(f\"Retrieved training data from Feature View '{feature_view_name}'\")\n",
    "            return X, y\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import joblib\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from WattPredictor.utils.helpers import create_directories, save_json\n",
    "from WattPredictor.utils.exception import CustomException\n",
    "from WattPredictor import logger\n",
    "\n",
    "\n",
    "class ModelEvaluation:\n",
    "    def __init__(self, config: ModelEvaluationConfig, feature_store_config):\n",
    "        self.config = config\n",
    "        self.feature_store_config = feature_store_config\n",
    "        self.feature_store = FeatureStore(feature_store_config)\n",
    "\n",
    "        mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "        mlflow.set_experiment(\"Electricity Demand Prediction\")\n",
    "        logger.info(\"MLflow tracking setup complete.\")\n",
    "\n",
    "    def download_inputs(self):\n",
    "        try:\n",
    "\n",
    "            self.feature_store.dataset_api.download(\"Resources/wattpredictor_artifacts/model.joblib/model.joblib\", overwrite=True)\n",
    "            self.feature_store.dataset_api.download(\"Resources/wattpredictor_artifacts/test_x.parquet/test_x.parquet\", overwrite=True)\n",
    "            self.feature_store.dataset_api.download(\"Resources/wattpredictor_artifacts/test_y.parquet/test_y.parquet\", overwrite=True)\n",
    "\n",
    "            test_x = pd.read_parquet(self.config.x_transform)\n",
    "            test_y = pd.read_parquet(self.config.y_transform)\n",
    "            \n",
    "            test_x = test_x.values\n",
    "            test_y = test_y.squeeze().values \n",
    "            model = joblib.load(self.config.model_path)\n",
    "\n",
    "            logger.info(f'shape of train_x:{test_x.shape}, train_y:{test_y.shape}')\n",
    "\n",
    "            return test_x,test_y, model\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def evaluate(self):\n",
    "        try:\n",
    "            test_x,test_y, model = self.download_inputs()\n",
    "\n",
    "\n",
    "            # Predict\n",
    "            preds = model.predict(test_x)\n",
    "\n",
    "            # Metrics\n",
    "            metrics = {\n",
    "                \"mse\": mean_squared_error(test_y, preds),\n",
    "                \"mae\": mean_absolute_error(test_y, preds),\n",
    "                \"rmse\": np.sqrt(mean_squared_error(test_y, preds)),\n",
    "                \"mape\": np.mean(np.abs((test_y - preds) / test_y)) * 100 if np.any(test_y != 0) else np.inf,\n",
    "                \"r2_score\": r2_score(test_y, preds),\n",
    "                \"adjusted_r2\": 1 - (1 - r2_score(test_y, preds)) * (len(test_y) - 1) / (len(test_y) - test_x.shape[1] - 1)\n",
    "            }\n",
    "\n",
    "            create_directories([Path(self.config.metrics_path).parent])\n",
    "            save_json(Path(self.config.metrics_path), metrics)\n",
    "\n",
    "            logger.info(f\"ðŸ“Š Evaluation Metrics: {metrics}\")\n",
    "\n",
    "            # Log to MLflow\n",
    "            with mlflow.start_run(run_name=\"Model Evaluation\"):\n",
    "                mlflow.log_metrics({k: float(v) for k, v in metrics.items()})\n",
    "                mlflow.set_tag(\"stage\", \"evaluation\")\n",
    "                mlflow.log_artifact(self.config.metrics_path)\n",
    "                mlflow.log_artifact(self.config.model_path)\n",
    "\n",
    "            logger.info(\"âœ… Model evaluation complete and metrics logged.\")\n",
    "            return metrics\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-11 15:05:53,024: INFO: helpers: yaml file: config_file\\config.yaml loaded successfully]\n",
      "[2025-07-11 15:05:53,028: INFO: helpers: yaml file: config_file\\schema.yaml loaded successfully]\n",
      "[2025-07-11 15:05:53,031: INFO: helpers: yaml file: config_file\\params.yaml loaded successfully]\n",
      "[2025-07-11 15:05:53,032: INFO: helpers: created directory at: artifacts]\n",
      "[2025-07-11 15:05:53,034: INFO: external: Initializing external client]\n",
      "[2025-07-11 15:05:53,036: INFO: external: Base URL: https://c.app.hopsworks.ai:443]\n",
      "[2025-07-11 15:05:55,914: INFO: python: Python Engine initialized.]\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1237149\n",
      "[2025-07-11 15:05:58,478: INFO: 468788050: Connected to Hopsworks Feature Store: JavithNaseem]\n",
      "[2025-07-11 15:05:58,485: WARNING: file_store: Malformed experiment '141997247217478997'. Detailed error Yaml file '.\\mlruns\\141997247217478997\\meta.yaml' does not exist.]\n",
      "Traceback (most recent call last):\n",
      "  File \"f:\\Program Files\\anaconda\\envs\\WattPredictor\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 356, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"f:\\Program Files\\anaconda\\envs\\WattPredictor\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 454, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"f:\\Program Files\\anaconda\\envs\\WattPredictor\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1595, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"f:\\Program Files\\anaconda\\envs\\WattPredictor\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1588, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"f:\\Program Files\\anaconda\\envs\\WattPredictor\\lib\\site-packages\\mlflow\\utils\\yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file '.\\mlruns\\141997247217478997\\meta.yaml' does not exist.\n",
      "[2025-07-11 15:05:58,497: INFO: 1575915400: MLflow tracking setup complete.]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8876ccd0549043d4b3091668f32409e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/1216576 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73222eaa1d594b0baa6ea7babb2fc712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/5889601 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-11 15:08:23,798: WARNING: connectionpool: Retrying (Retry(total=0, connect=None, read=False, redirect=None, status=None)) after connection broken by 'MustRedialError('Remote peer just closed our connection, probably for not answering to unsolicited packet. (None)')': /hopsworks-api/api/project/1237149/dataset/Resources%2Fwattpredictor_artifacts%2Ftest_y.parquet%2Ftest_y.parquet]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62d6f2e88164119a7ac343f292e0329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/9758 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-11 15:08:26,080: INFO: 1575915400: shape of train_x:(2112, 674), train_y:(2112,)]\n",
      "[2025-07-11 15:08:26,085: WARNING: warnings: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "]\n",
      "[2025-07-11 15:08:31,912: INFO: helpers: created directory at: artifacts\\model_evaluation]\n",
      "[2025-07-11 15:08:31,915: INFO: helpers: json file saved at: artifacts\\model_evaluation\\metrics.json]\n",
      "[2025-07-11 15:08:31,916: INFO: 1575915400: ðŸ“Š Evaluation Metrics: {'mse': 8741.435722876593, 'mae': 51.382026308241464, 'rmse': 93.49564547547973, 'mape': 4.428398874064529, 'r2_score': 0.9944144248200268, 'adjusted_r2': 0.9917946073730527}]\n",
      "[2025-07-11 15:08:32,314: INFO: 1575915400: âœ… Model evaluation complete and metrics logged.]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_evaluation_config = config.get_model_evaluation_config()\n",
    "    feature_store_config = config.get_feature_store_config()\n",
    "    model_evaluation = ModelEvaluation(config=model_evaluation_config, feature_store_config=feature_store_config)\n",
    "    model_evaluation.evaluate()\n",
    "except Exception as e:\n",
    "    raise CustomException(str(e), sys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WattPredictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
