{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d21fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5a82b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b945b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(os.getcwd(), \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db4d2e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from WattPredictor.utils.helpers import *\n",
    "from WattPredictor.utils.exception import *\n",
    "from WattPredictor.constants import *\n",
    "from WattPredictor.utils.logging import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e87464eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_file: Path\n",
    "    status_file: str\n",
    "    label_encoder: Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class FeatureStoreConfig:\n",
    "    hopsworks_project_name: str\n",
    "    hopsworks_api_key: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04e5eb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath=CONFIG_PATH,\n",
    "                       params_filepath=PARAMS_PATH,\n",
    "                       schema_filepath=SCHEMA_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "        params = self.params.training\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            data_file=Path(config.data_file),\n",
    "            status_file=Path(config.status_file),\n",
    "            label_encoder=Path(config.label_encoder)\n",
    "        )\n",
    "\n",
    "        return data_transformation_config\n",
    "\n",
    "    def get_feature_store_config(self) -> FeatureStoreConfig:\n",
    "\n",
    "        config = self.config.feature_store\n",
    "\n",
    "        feature_store_config = FeatureStoreConfig(\n",
    "                hopsworks_project_name=config.hopsworks_project_name,\n",
    "                hopsworks_api_key=os.environ['hopsworks_api_key'],\n",
    "        )\n",
    "\n",
    "        return feature_store_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cf32f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from WattPredictor.config.feature_config import FeatureStoreConfig\n",
    "from WattPredictor.utils.exception import CustomException\n",
    "\n",
    "class FeatureStore:\n",
    "    def __init__(self, config:FeatureStoreConfig):\n",
    "        try:\n",
    "            self.config = config\n",
    "            self.connect()\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def connect(self):\n",
    "        try:\n",
    "            self.project = hopsworks.login(\n",
    "                project=self.config.hopsworks_project_name,\n",
    "                api_key_value=self.config.hopsworks_api_key\n",
    "            )\n",
    "            self.feature_store = self.project.get_feature_store()\n",
    "            self.dataset_api = self.project.get_dataset_api()\n",
    "            logger.info(f\"Connected to Hopsworks Feature Store: {self.config.hopsworks_project_name}\")\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "\n",
    "    def create_feature_group(self, name, df, primary_key, event_time, description, online_enabled=True, version=1):\n",
    "        \"\"\"\n",
    "        Create or update a feature group with proper error handling for metadata inconsistencies\n",
    "        \"\"\"\n",
    "        try:\n",
    "            try:\n",
    "                fg = self.feature_store.get_feature_group(name=name, version=version)\n",
    "                if fg is not None:\n",
    "                    logger.info(f\"Feature Group '{name}' v{version} exists. Attempting to insert data.\")\n",
    "                    try:\n",
    "                        fg.insert(df)\n",
    "                        logger.info(f\"Successfully inserted data into existing Feature Group '{name}' v{version}\")\n",
    "                        return fg\n",
    "                    except Exception as insert_error:\n",
    "                        logger.warning(f\"Insert failed: {insert_error}. Attempting to delete and recreate.\")\n",
    "                        try:\n",
    "                            fg.delete()\n",
    "                            logger.info(f\"Deleted corrupted Feature Group '{name}' v{version}\")\n",
    "                        except Exception as delete_error:\n",
    "                            logger.warning(f\"Delete failed: {delete_error}\")\n",
    "            except Exception as get_error:\n",
    "                logger.info(f\"Feature Group '{name}' v{version} does not exist or is corrupted: {get_error}\")\n",
    "\n",
    "            # Create new feature group\n",
    "            logger.info(f\"Creating new Feature Group '{name}' v{version}\")\n",
    "            try:\n",
    "                fg = self.feature_store.create_feature_group(\n",
    "                    name=name,\n",
    "                    version=version,\n",
    "                    primary_key=primary_key,\n",
    "                    event_time=event_time,\n",
    "                    description=description,\n",
    "                    online_enabled=online_enabled\n",
    "                )\n",
    "                fg.save(df)\n",
    "                logger.info(f\"Successfully created Feature Group '{name}' v{version}\")\n",
    "                return fg\n",
    "                \n",
    "            except Exception as create_error:\n",
    "                if \"already exists\" in str(create_error):\n",
    "                    logger.error(f\"Hive table exists but metadata is corrupted. Manual cleanup required.\")\n",
    "                    version += 1\n",
    "                    logger.info(f\"Attempting to create with version {version}\")\n",
    "                    fg = self.feature_store.create_feature_group(\n",
    "                        name=name,\n",
    "                        version=version,\n",
    "                        primary_key=primary_key,\n",
    "                        event_time=event_time,\n",
    "                        description=description,\n",
    "                        online_enabled=online_enabled\n",
    "                    )\n",
    "                    fg.save(df)\n",
    "                    logger.info(f\"Successfully created Feature Group '{name}' v{version}\")\n",
    "                    return fg\n",
    "                else:\n",
    "                    raise create_error\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to create/update Feature Group '{name}': {str(e)}\")\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "\n",
    "\n",
    "    def create_feature_view(self, name: str, feature_group_name: str, features: list):\n",
    "        try:\n",
    "            fg = self.feature_store.get_feature_group(name=feature_group_name, version=1)\n",
    "            fv = self.feature_store.get_or_create_feature_view(\n",
    "                name=name,\n",
    "                version=1,\n",
    "                query=fg.select(features),\n",
    "                description=f\"Feature View for {name}\"\n",
    "            )\n",
    "            logger.info(f\"Feature View '{name}' created successfully\")\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "        \n",
    "\n",
    "    def save_training_dataset(self, feature_view_name, version_description, output_format=\"csv\"):\n",
    "        try:\n",
    "            fv = self.feature_store.get_feature_view(name=feature_view_name, version=1)\n",
    "            td = fv.create_training_data(\n",
    "                description=version_description,\n",
    "                data_format=output_format,\n",
    "                write_options={\"wait_for_job\": True}\n",
    "            )\n",
    "            logger.info(f\"Training dataset created for Feature View '{feature_view_name}'.\")\n",
    "            return td\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "        \n",
    "    def load_latest_training_dataset(self, feature_view_name):\n",
    "        try:\n",
    "            fv = self.feature_store.get_feature_view(name=feature_view_name, version=1)\n",
    "            return fv.training_data()\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "\n",
    "    def upload_file_safely(self, local_path: str, target_name: str):\n",
    "\n",
    "        try:\n",
    "            self.dataset_api.upload(\n",
    "                local_path,\n",
    "                f\"Resources/wattpredictor_artifacts/{target_name}\",\n",
    "                overwrite=True \n",
    "            )\n",
    "            logger.info(f\"Uploaded file to Feature Store: {target_name}\")\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "\n",
    "    def get_training_data(self, feature_view_name: str):\n",
    "        try:\n",
    "            fv = self.feature_store.get_feature_view(name=feature_view_name, version=1)\n",
    "            X, y = fv.training_data()\n",
    "            logger.info(f\"Retrieved training data from Feature View '{feature_view_name}'\")\n",
    "            return X, y\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "    \n",
    "    \n",
    "    def get_online_features(self, feature_view_name, key_dict: dict, version=1):\n",
    "        try:\n",
    "            fv = self.feature_store.get_feature_view(name=feature_view_name, version=version)\n",
    "            if fv is None:\n",
    "                logger.error(f\"[Online Fetch] Feature View '{feature_view_name}' v{version} not found.\")\n",
    "                raise CustomException(f\"Feature View '{feature_view_name}' v{version} is None\", sys)\n",
    "\n",
    "            expected_primary_keys = [\"date_str\", \"sub_region_code\"]\n",
    "            \n",
    "            key_values = [key_dict[key] for key in expected_primary_keys]\n",
    "            \n",
    "            try:\n",
    "                result = fv.get_feature_vector(key_dict)\n",
    "                logger.info(f\"[Online Fetch] Fetched online features using get_feature_vector for {key_dict}: {result}\")\n",
    "                return result\n",
    "            except Exception as vector_error:\n",
    "                logger.warning(f\"get_feature_vector failed: {vector_error}, trying get_serving_vector\")\n",
    "                \n",
    "                result = fv.get_serving_vector(key_values).to_dict()\n",
    "                logger.info(f\"[Online Fetch] Fetched online features using get_serving_vector for {key_dict}: {result}\")\n",
    "                return result\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[Online Fetch] Failed to fetch online features for {feature_view_name} with key {key_dict}\")\n",
    "            raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42bdf4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "from WattPredictor.utils.feature import feature_store_instance\n",
    "from WattPredictor.utils.helpers import create_directories, save_bin\n",
    "from WattPredictor.utils.exception import CustomException\n",
    "\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "        self.feature_store = feature_store_instance()\n",
    "\n",
    "\n",
    "    def check_status(self):\n",
    "        try:\n",
    "            with open(self.config.status_file, 'r') as f:\n",
    "                status_data = json.load(f)\n",
    "            return status_data.get(\"validation_status\", False)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Validation status check failed: {e}\")\n",
    "            return False\n",
    "\n",
    "    def basic_preprocessing(self) -> pd.DataFrame:\n",
    "        try:\n",
    "            fg = self.feature_store.feature_store.get_feature_group(name=\"elec_wx_demand\", version=2)\n",
    "            df = fg.read()\n",
    "            le = LabelEncoder()\n",
    "            df['sub_region_code'] = le.fit_transform(df['subba'])\n",
    "            df.rename(columns={'subba': 'sub_region', 'value': 'demand'}, inplace=True)\n",
    "            df = df[['date_str','date', 'sub_region_code', 'demand', 'temperature_2m']]\n",
    "\n",
    "            create_directories([os.path.dirname(self.config.label_encoder)])\n",
    "            save_bin(le, self.config.label_encoder)\n",
    "            self.feature_store.upload_file_safely(self.config.label_encoder, \"label_encoder.pkl\")\n",
    "\n",
    "            logger.info(\"Label encoding and preprocessing complete.\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def feature_engineering(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        try:\n",
    "            df['date'] = pd.to_datetime(df['date'], utc=True)\n",
    "            \n",
    "            df['hour'] = df['date'].dt.hour\n",
    "            df['day_of_week'] = df['date'].dt.dayofweek\n",
    "            df['month'] = df['date'].dt.month\n",
    "            df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "            holidays = calendar().holidays(start=df['date'].min(), end=df['date'].max())\n",
    "            df['is_holiday'] = df['date'].isin(holidays).astype(int)\n",
    "\n",
    "            \n",
    "            self.feature_store.create_feature_group(\n",
    "                name=\"elec_wx_features\",\n",
    "                df=df,\n",
    "                primary_key=[\"date_str\",\"sub_region_code\"],\n",
    "                event_time=\"date\",\n",
    "                description=\"Engineered electricity demand features\",\n",
    "                online_enabled=True\n",
    "            )\n",
    "\n",
    "            logger.info(\"Feature group created and feature engineering complete.\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def transform(self):\n",
    "        if not self.check_status():\n",
    "            raise CustomException(\"Validation failed. Aborting transformation.\", sys)\n",
    "        try:\n",
    "            df = self.feature_engineering(self.basic_preprocessing())\n",
    "            df.sort_values(\"date\", inplace=True)\n",
    "\n",
    "            self.feature_store.create_feature_view(\n",
    "                name=\"elec_wx_features_view\",\n",
    "                feature_group_name=\"elec_wx_features\",\n",
    "                features=[\n",
    "                    \"date\", \"sub_region_code\", \"demand\", \"temperature_2m\",\n",
    "                    \"hour\", \"day_of_week\", \"month\", \"is_weekend\", \"is_holiday\"\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            self.feature_store.save_training_dataset(\n",
    "                feature_view_name=\"elec_wx_features_view\",\n",
    "                version_description=\"initial training dataset with all features\",\n",
    "                output_format=\"csv\"\n",
    "            )\n",
    "\n",
    "            logger.info(\"Feature view + training dataset saved successfully.\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d60c4364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-16 16:39:54,841: INFO: helpers: yaml file: config_file\\config.yaml loaded successfully]\n",
      "[2025-07-16 16:39:54,856: INFO: helpers: yaml file: config_file\\params.yaml loaded successfully]\n",
      "[2025-07-16 16:39:54,856: INFO: helpers: yaml file: config_file\\schema.yaml loaded successfully]\n",
      "[2025-07-16 16:39:54,856: INFO: helpers: created directory at: artifacts]\n",
      "[2025-07-16 16:39:54,856: INFO: helpers: created directory at: artifacts/data_transformation]\n",
      "[2025-07-16 16:39:54,875: INFO: helpers: yaml file: config_file\\config.yaml loaded successfully]\n",
      "[2025-07-16 16:39:54,878: INFO: helpers: yaml file: config_file\\params.yaml loaded successfully]\n",
      "[2025-07-16 16:39:54,884: INFO: helpers: yaml file: config_file\\schema.yaml loaded successfully]\n",
      "[2025-07-16 16:39:54,887: INFO: external: Initializing external client]\n",
      "[2025-07-16 16:39:54,889: INFO: external: Base URL: https://c.app.hopsworks.ai:443]\n",
      "[2025-07-16 16:39:57,945: INFO: python: Python Engine initialized.]\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1240214\n",
      "[2025-07-16 16:40:00,734: INFO: feature_store: Connected to Hopsworks Feature Store: WattPredictor]\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (3.25s) \n",
      "[2025-07-16 16:40:07,682: INFO: helpers: created directory at: artifacts\\data_transformation]\n",
      "[2025-07-16 16:40:07,698: INFO: helpers: binary file saved at: artifacts\\data_transformation\\label_encoder.pkl]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6f2eab12e6491395ae314852aef605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading f:\\WattPredictor\\artifacts\\data_transformation\\label_encoder.pkl: 0.000%|          | 0/549 elapsed<0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-16 16:40:10,499: INFO: feature_store: Uploaded file to Feature Store: label_encoder.pkl]\n",
      "[2025-07-16 16:40:10,499: INFO: 1290199015: Label encoding and preprocessing complete.]\n",
      "[2025-07-16 16:40:10,834: INFO: feature_store: Creating new Feature Group 'elec_wx_features' v1]\n",
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1240214/fs/1223749/fg/1495490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 39545/39545 | Elapsed Time: 00:11 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: elec_wx_features_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1240214/jobs/named/elec_wx_features_1_offline_fg_materialization/executions\n",
      "[2025-07-16 16:41:06,100: INFO: feature_store: Successfully created Feature Group 'elec_wx_features' v1]\n",
      "[2025-07-16 16:41:06,103: INFO: 1290199015: Feature group created and feature engineering complete.]\n",
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1240214/fs/1223749/fv/elec_wx_features_view/version/1\n",
      "[2025-07-16 16:41:08,910: INFO: feature_store: Feature View 'elec_wx_features_view' created successfully]\n",
      "Training dataset job started successfully, you can follow the progress at \n",
      "http://c.app.hopsworks.ai/p/1240214/jobs/named/elec_wx_features_view_1_create_fv_td_16072025111157/executions\n",
      "[2025-07-16 16:41:22,541: INFO: execution_engine: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED]\n",
      "[2025-07-16 16:41:25,857: INFO: execution_engine: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED]\n",
      "[2025-07-16 16:42:32,054: INFO: execution_engine: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED]\n",
      "[2025-07-16 16:42:32,340: INFO: execution_engine: Waiting for log aggregation to finish.]\n",
      "[2025-07-16 16:42:59,425: INFO: execution_engine: Execution finished successfully.]\n",
      "[2025-07-16 16:42:59,740: WARNING: warnings: VersionWarning: Incremented version to `1`.\n",
      "]\n",
      "[2025-07-16 16:42:59,740: INFO: feature_store: Training dataset created for Feature View 'elec_wx_features_view'.]\n",
      "[2025-07-16 16:42:59,740: INFO: 1290199015: Feature view + training dataset saved successfully.]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "        config = ConfigurationManager()\n",
    "        data_transformation_config = config.get_data_transformation_config()\n",
    "        feature_store_config = config.get_feature_store_config()\n",
    "        data_transformation = DataTransformation(config=data_transformation_config)\n",
    "        df= data_transformation.transform()\n",
    "\n",
    "except Exception as e:\n",
    "        raise CustomException(str(e), sys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WattPredictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
