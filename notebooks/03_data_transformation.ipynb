{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d21fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5a82b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b945b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(os.getcwd(), \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db4d2e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from WattPredictor.utils.helpers import *\n",
    "from WattPredictor.utils.exception import *\n",
    "from WattPredictor.constants import *\n",
    "from WattPredictor import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e87464eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_file: Path\n",
    "    status_file: str\n",
    "    label_encoder: Path\n",
    "    input_seq_len: int\n",
    "    step_size: int\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class FeatureStoreConfig:\n",
    "    hopsworks_project_name: str\n",
    "    hopsworks_api_key: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04e5eb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath=CONFIG_PATH,\n",
    "                       params_filepath=PARAMS_PATH,\n",
    "                       schema_filepath=SCHEMA_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "        params = self.params.model_trainer\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            data_file=Path(config.data_file),\n",
    "            status_file=Path(config.status_file),\n",
    "            label_encoder=Path(config.label_encoder),\n",
    "            input_seq_len=params.input_seq_len,\n",
    "            step_size=params.step_size\n",
    "        )\n",
    "\n",
    "        return data_transformation_config\n",
    "\n",
    "    def get_feature_store_config(self) -> FeatureStoreConfig:\n",
    "\n",
    "        config = self.config.feature_store\n",
    "\n",
    "        feature_store_config = FeatureStoreConfig(\n",
    "                hopsworks_project_name=config.hopsworks_project_name,\n",
    "                hopsworks_api_key=os.environ['hopsworks_api_key'],\n",
    "        )\n",
    "\n",
    "        return feature_store_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf32f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "import pandas as pd\n",
    "import sys\n",
    "from WattPredictor.utils.exception import CustomException\n",
    "from WattPredictor import logger\n",
    "\n",
    "\n",
    "class FeatureStore:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.connect()\n",
    "\n",
    "    def connect(self):\n",
    "        try:\n",
    "            self.project = hopsworks.login(\n",
    "                project=self.config.hopsworks_project_name,\n",
    "                api_key_value=self.config.hopsworks_api_key\n",
    "            )\n",
    "            self.feature_store = self.project.get_feature_store()\n",
    "            self.dataset_api = self.project.get_dataset_api()\n",
    "            logger.info(f\"Connected to Hopsworks Feature Store: {self.config.hopsworks_project_name}\")\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def create_or_update_feature_group(self, name, df, primary_key, event_time, description, online=False):\n",
    "        \"\"\"\n",
    "        Alternative method that handles feature group creation/update more robustly\n",
    "        \"\"\"\n",
    "        try:\n",
    "            import time\n",
    "            \n",
    "            # Step 1: Check if feature group exists\n",
    "            fg = None\n",
    "            try:\n",
    "                fg = self.feature_store.get_feature_group(name=name, version=1)\n",
    "                \n",
    "                # Additional check to ensure fg is not None\n",
    "                if fg is not None:\n",
    "                    logger.info(f\"Feature Group '{name}' found. Will insert new data...\")\n",
    "                    # Insert data directly if feature group exists\n",
    "                    fg.insert(df, write_options={\"wait_for_job\": True})\n",
    "                    logger.info(f\"Data successfully inserted into existing Feature Group '{name}'.\")\n",
    "                    return fg\n",
    "                else:\n",
    "                    logger.info(f\"Feature Group '{name}' returned None, treating as not found.\")\n",
    "                    raise Exception(\"Feature group not found\")\n",
    "                    \n",
    "            except Exception as get_error:\n",
    "                logger.info(f\"Feature Group '{name}' not found: {str(get_error)}\")\n",
    "                logger.info(\"Proceeding to create new feature group...\")\n",
    "\n",
    "            # Step 2: Create feature group if it doesn't exist\n",
    "            try:\n",
    "                # Use get_or_create_feature_group if available, otherwise create_feature_group\n",
    "                if hasattr(self.feature_store, 'get_or_create_feature_group'):\n",
    "                    fg = self.feature_store.get_or_create_feature_group(\n",
    "                        name=name,\n",
    "                        version=1,\n",
    "                        primary_key=primary_key,\n",
    "                        event_time=event_time,\n",
    "                        description=description,\n",
    "                        online_enabled=online\n",
    "                    )\n",
    "                    logger.info(f\"Feature Group '{name}' created using get_or_create_feature_group\")\n",
    "                else:\n",
    "                    # Traditional create approach\n",
    "                    fg = self.feature_store.create_feature_group(\n",
    "                        name=name,\n",
    "                        version=1,\n",
    "                        primary_key=primary_key,\n",
    "                        event_time=event_time,\n",
    "                        description=description,\n",
    "                        online_enabled=online\n",
    "                    )\n",
    "                    logger.info(f\"Feature Group '{name}' created using create_feature_group\")\n",
    "\n",
    "            except Exception as create_error:\n",
    "                logger.error(f\"Failed to create feature group '{name}': {str(create_error)}\")\n",
    "                raise create_error\n",
    "\n",
    "            if fg is None:\n",
    "                raise Exception(f\"Feature group '{name}' is None after creation\")\n",
    "\n",
    "            logger.info(f\"Inserting {len(df)} rows into Feature Group '{name}'...\")\n",
    "            fg.insert(df, write_options={\"wait_for_job\": True})\n",
    "            logger.info(f\"Data successfully inserted into Feature Group '{name}'.\")\n",
    "            \n",
    "            return fg\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in create_or_update_feature_group for '{name}': {str(e)}\")\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def create_feature_view(self, name, feature_group_name, features):\n",
    "        try:\n",
    "            try:\n",
    "                existing_fv = self.feature_store.get_feature_view(name=name, version=1)\n",
    "                if existing_fv is not None:\n",
    "                    existing_fv.delete()\n",
    "                    logger.info(f\"Deleted existing Feature View '{name}' for clean recreation.\")\n",
    "            except Exception as delete_error:\n",
    "                logger.warning(f\"No existing Feature View to delete: {delete_error}\")\n",
    "\n",
    "            fg = self.feature_store.get_feature_group(name=feature_group_name, version=1)\n",
    "            query = fg.select(features)\n",
    "            fv = self.feature_store.create_feature_view(\n",
    "                name=name,\n",
    "                version=1,\n",
    "                query=query,\n",
    "                description=f\"Feature View for {feature_group_name}\"\n",
    "            )\n",
    "            logger.info(f\"Feature View '{name}' created successfully.\")\n",
    "            return fv\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def save_training_dataset(self, feature_view_name, version_description, output_format=\"csv\"):\n",
    "        try:\n",
    "            fv = self.feature_store.get_feature_view(name=feature_view_name, version=1)\n",
    "            td = fv.create_training_data(\n",
    "                description=version_description,\n",
    "                data_format=output_format,\n",
    "                write_options={\"wait_for_job\": True}\n",
    "            )\n",
    "            logger.info(f\"Training dataset version for Feature View '{feature_view_name}' created.\")\n",
    "            return td\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def load_latest_training_dataset(self, feature_view_name):\n",
    "        try:\n",
    "            fv = self.feature_store.get_feature_view(name=feature_view_name, version=1)\n",
    "            return fv.training_data()\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def get_online_features(self, feature_view_name, key_dict: dict):\n",
    "        try:\n",
    "            fv = self.feature_store.get_feature_view(name=feature_view_name, version=1)\n",
    "            return fv.get_online_features(key_dict)\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def upload_file_safely(self, local_path: str, target_name: str):\n",
    "        try:\n",
    "            self.dataset_api.upload(\n",
    "                local_path,\n",
    "                f\"Resources/wattpredictor_artifacts/{target_name}\",\n",
    "                overwrite=True\n",
    "            )\n",
    "            logger.info(f\"Uploaded file to Feature Store: {target_name}\")\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42bdf4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "from WattPredictor.utils.helpers import create_directories, save_bin\n",
    "from WattPredictor.utils.exception import CustomException\n",
    "from WattPredictor import logger\n",
    "\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig, feature_store_config: FeatureStoreConfig):\n",
    "        self.config = config\n",
    "        self.feature_store = FeatureStore(feature_store_config)\n",
    "\n",
    "    def check_status(self):\n",
    "        try:\n",
    "            with open(self.config.status_file, 'r') as f:\n",
    "                status_data = json.load(f)\n",
    "            return status_data.get(\"validation_status\", False)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Validation status check failed: {e}\")\n",
    "            return False\n",
    "\n",
    "    def basic_preprocessing(self) -> pd.DataFrame:\n",
    "        try:\n",
    "            fg = self.feature_store.feature_store.get_feature_group(name=\"elec_wx_demand\", version=1)\n",
    "            df = fg.read()\n",
    "            df = df[['date', 'subba', 'value', 'temperature_2m']]\n",
    "\n",
    "            le = LabelEncoder()\n",
    "            df['sub_region_code'] = le.fit_transform(df['subba'])\n",
    "            df.rename(columns={'subba': 'sub_region', 'value': 'demand'}, inplace=True)\n",
    "            df = df[['date', 'sub_region_code', 'demand', 'temperature_2m']]\n",
    "\n",
    "            create_directories([os.path.dirname(self.config.label_encoder)])\n",
    "            save_bin(le, self.config.label_encoder)\n",
    "            self.feature_store.upload_file_safely(self.config.label_encoder, \"label_encoder.pkl\")\n",
    "\n",
    "            logger.info(\"Label encoding and preprocessing complete.\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def feature_engineering(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        try:\n",
    "            # Convert date to datetime if not already\n",
    "            df['date'] = pd.to_datetime(df['date'], utc=True)\n",
    "            \n",
    "            # Create time-based features\n",
    "            df['hour'] = df['date'].dt.hour\n",
    "            df['day_of_week'] = df['date'].dt.dayofweek\n",
    "            df['month'] = df['date'].dt.month\n",
    "            df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "            # Create holiday feature\n",
    "            holidays = calendar().holidays(start=df['date'].min(), end=df['date'].max())\n",
    "            df['is_holiday'] = df['date'].isin(holidays).astype(int)\n",
    "\n",
    "            # Debug information\n",
    "            logger.info(f\"DataFrame shape: {df.shape}\")\n",
    "            logger.info(f\"DataFrame columns: {df.columns.tolist()}\")\n",
    "            logger.info(f\"Date column type: {df['date'].dtype}\")\n",
    "            logger.info(f\"Sample data:\\n{df.head()}\")\n",
    "            \n",
    "            # Fixed: Use the correct method name\n",
    "            self.feature_store.create_or_update_feature_group(\n",
    "                name=\"elec_wx_features\",\n",
    "                df=df,\n",
    "                primary_key=[\"sub_region_code\"],\n",
    "                event_time=\"date\",\n",
    "                description=\"Engineered electricity demand features\",\n",
    "                online=True\n",
    "            )\n",
    "\n",
    "            logger.info(\"Feature group created and feature engineering complete.\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def transform(self):\n",
    "        if not self.check_status():\n",
    "            raise CustomException(\"Validation failed. Aborting transformation.\", sys)\n",
    "        try:\n",
    "            df = self.feature_engineering(self.basic_preprocessing())\n",
    "            df.sort_values(\"date\", inplace=True)\n",
    "\n",
    "            self.feature_store.create_feature_view(\n",
    "                name=\"elec_wx_features_view\",\n",
    "                feature_group_name=\"elec_wx_features\",\n",
    "                features=[\n",
    "                    \"date\", \"sub_region_code\", \"demand\", \"temperature_2m\",\n",
    "                    \"hour\", \"day_of_week\", \"month\", \"is_weekend\", \"is_holiday\"\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            self.feature_store.save_training_dataset(\n",
    "                feature_view_name=\"elec_wx_features_view\",\n",
    "                version_description=\"initial training dataset with all features\",\n",
    "                output_format=\"csv\"\n",
    "            )\n",
    "\n",
    "            logger.info(\"Feature view + training dataset saved successfully.\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d60c4364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-12 17:32:07,851: INFO: helpers: yaml file: config_file\\config.yaml loaded successfully]\n",
      "[2025-07-12 17:32:07,855: INFO: helpers: yaml file: config_file\\params.yaml loaded successfully]\n",
      "[2025-07-12 17:32:07,855: INFO: helpers: yaml file: config_file\\schema.yaml loaded successfully]\n",
      "[2025-07-12 17:32:07,861: INFO: helpers: created directory at: artifacts]\n",
      "[2025-07-12 17:32:07,862: INFO: helpers: created directory at: artifacts/data_transformation]\n",
      "[2025-07-12 17:32:07,864: INFO: external: Initializing external client]\n",
      "[2025-07-12 17:32:07,865: INFO: external: Base URL: https://c.app.hopsworks.ai:443]\n",
      "[2025-07-12 17:32:09,489: WARNING: warnings: UserWarning: The installed hopsworks client version 4.3.1 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-12 17:32:10,535: INFO: python: Python Engine initialized.]\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1237149\n",
      "[2025-07-12 17:32:12,286: INFO: 1554228661: Connected to Hopsworks Feature Store: JavithNaseem]\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (3.47s) \n",
      "[2025-07-12 17:32:18,881: INFO: helpers: created directory at: artifacts\\data_transformation]\n",
      "[2025-07-12 17:32:18,883: INFO: helpers: binary file saved at: artifacts\\data_transformation\\label_encoder.pkl]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52745f7088dc46beaddbe0c947f6b671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading f:\\WattPredictor\\artifacts\\data_transformation\\label_encoder.pkl: 0.000%|          | 0/549 elapsed<0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-12 17:32:21,525: INFO: 1554228661: Uploaded file to Feature Store: label_encoder.pkl]\n",
      "[2025-07-12 17:32:21,533: INFO: 1405442928: Label encoding and preprocessing complete.]\n",
      "[2025-07-12 17:32:21,586: INFO: 1405442928: DataFrame shape: (39281, 9)]\n",
      "[2025-07-12 17:32:21,589: INFO: 1405442928: DataFrame columns: ['date', 'sub_region_code', 'demand', 'temperature_2m', 'hour', 'day_of_week', 'month', 'is_weekend', 'is_holiday']]\n",
      "[2025-07-12 17:32:21,592: INFO: 1405442928: Date column type: datetime64[us, UTC]]\n",
      "[2025-07-12 17:32:21,592: INFO: 1405442928: Sample data:\n",
      "                       date  sub_region_code demand  temperature_2m  hour  \\\n",
      "0 2025-02-07 18:00:00+00:00                4   1033           2.146    18   \n",
      "1 2025-02-10 06:00:00+00:00                0   1647          -1.704     6   \n",
      "2 2025-04-07 01:00:00+00:00                2   1752          10.746     1   \n",
      "3 2025-02-14 20:00:00+00:00                4    966           0.296    20   \n",
      "4 2025-02-16 18:00:00+00:00                0   1804           4.546    18   \n",
      "\n",
      "   day_of_week  month  is_weekend  is_holiday  \n",
      "0            4      2           0           0  \n",
      "1            0      2           0           0  \n",
      "2            0      4           0           0  \n",
      "3            4      2           0           0  \n",
      "4            6      2           1           0  ]\n",
      "[2025-07-12 17:32:22,031: INFO: 1554228661: Feature Group 'elec_wx_features' found. Will insert new data...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 39281/39281 | Elapsed Time: 00:03 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: elec_wx_features_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1237149/jobs/named/elec_wx_features_1_offline_fg_materialization/executions\n",
      "[2025-07-12 17:32:44,625: INFO: execution_engine: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED]\n",
      "[2025-07-12 17:32:47,925: INFO: execution_engine: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED]\n",
      "[2025-07-12 17:34:36,295: INFO: execution_engine: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED]\n",
      "[2025-07-12 17:34:36,567: INFO: execution_engine: Waiting for log aggregation to finish.]\n",
      "[2025-07-12 17:34:56,143: INFO: execution_engine: Execution finished successfully.]\n",
      "[2025-07-12 17:34:56,147: INFO: 1554228661: Data successfully inserted into existing Feature Group 'elec_wx_features'.]\n",
      "[2025-07-12 17:34:56,151: INFO: 1405442928: Feature group created and feature engineering complete.]\n",
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1237149/fs/1220685/fv/elec_wx_features_view/version/1\n",
      "[2025-07-12 17:34:58,745: INFO: 1554228661: Feature View 'elec_wx_features_view' created successfully.]\n",
      "Training dataset job started successfully, you can follow the progress at \n",
      "http://c.app.hopsworks.ai/p/1237149/jobs/named/elec_wx_features_view_1_create_fv_td_12072025120517/executions\n",
      "[2025-07-12 17:35:11,914: INFO: execution_engine: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED]\n",
      "[2025-07-12 17:35:15,197: INFO: execution_engine: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED]\n",
      "[2025-07-12 17:36:30,791: INFO: execution_engine: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED]\n",
      "[2025-07-12 17:36:31,051: INFO: execution_engine: Waiting for log aggregation to finish.]\n",
      "[2025-07-12 17:36:50,655: INFO: execution_engine: Execution finished successfully.]\n",
      "[2025-07-12 17:36:50,950: WARNING: warnings: VersionWarning: Incremented version to `1`.\n",
      "]\n",
      "[2025-07-12 17:36:50,952: INFO: 1554228661: Training dataset version for Feature View 'elec_wx_features_view' created.]\n",
      "[2025-07-12 17:36:50,954: INFO: 1405442928: Feature view + training dataset saved successfully.]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    feature_store_config = config.get_feature_store_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config,feature_store_config=feature_store_config)\n",
    "    df= data_transformation.transform()\n",
    "\n",
    "except Exception as e:\n",
    "    raise CustomException(str(e), sys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WattPredictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
