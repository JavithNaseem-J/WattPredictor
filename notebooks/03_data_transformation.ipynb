{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d21fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5a82b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b945b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(os.getcwd(), \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db4d2e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from WattPredictor.utils.helpers import *\n",
    "from WattPredictor.utils.exception import *\n",
    "from WattPredictor.constants import *\n",
    "from WattPredictor import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e87464eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_file: Path\n",
    "    status_file: str\n",
    "    label_encoder: Path\n",
    "    train_features: Path\n",
    "    test_features: Path\n",
    "    input_seq_len: int\n",
    "    step_size: int\n",
    "    cutoff_date: str\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class FeatureStoreConfig:\n",
    "    hopsworks_project_name: str\n",
    "    hopsworks_api_key: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04e5eb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath=CONFIG_PATH,\n",
    "                       params_filepath=PARAMS_PATH,\n",
    "                       schema_filepath=SCHEMA_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "        schema = self.schema\n",
    "        params = self.params.transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            data_file=Path(config.data_file),\n",
    "            status_file=Path(config.status_file),\n",
    "            label_encoder=Path(config.label_encoder),\n",
    "            train_features=Path(config.train_features),\n",
    "            test_features=Path(config.test_features),\n",
    "            input_seq_len=params.input_seq_len,\n",
    "            step_size=params.step_size,\n",
    "            cutoff_date=params.cutoff_date\n",
    "        )\n",
    "\n",
    "        return data_transformation_config\n",
    "    \n",
    "    def get_feature_store_config(self) -> FeatureStoreConfig:\n",
    "\n",
    "        config = self.config.feature_store\n",
    "\n",
    "        feature_store_config = FeatureStoreConfig(\n",
    "                hopsworks_project_name=config.hopsworks_project_name,\n",
    "                hopsworks_api_key=os.environ['hopsworks_api_key'],\n",
    "        )\n",
    "\n",
    "        return feature_store_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cf32f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from WattPredictor.utils.exception import CustomException\n",
    "from WattPredictor import logger\n",
    "\n",
    "class FeatureStore:\n",
    "    def __init__(self, config):\n",
    "        try:\n",
    "            self.config = config\n",
    "            self.connect()\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def connect(self):\n",
    "        try:\n",
    "            self.project = hopsworks.login(\n",
    "                project=self.config.hopsworks_project_name,\n",
    "                api_key_value=self.config.hopsworks_api_key\n",
    "            )\n",
    "            self.feature_store = self.project.get_feature_store()\n",
    "            self.dataset_api = self.project.get_dataset_api()\n",
    "            logger.info(f\"Connected to Hopsworks Feature Store: {self.config.hopsworks_project_name}\")\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def create_feature_group(self, name, df, primary_key, event_time, description):\n",
    "        try:\n",
    "            try:\n",
    "                fg = self.feature_store.get_feature_group(name=name, version=1)\n",
    "                logger.info(f\"Feature Group '{name}' already exists. Inserting data instead.\")\n",
    "                fg.insert(df)\n",
    "            except:\n",
    "                logger.info(f\"Feature Group '{name}' does not exist. Creating new one.\")\n",
    "                fg = self.feature_store.get_or_create_feature_group(\n",
    "                    name=name,\n",
    "                    version=1,\n",
    "                    primary_key=primary_key,\n",
    "                    event_time=event_time,\n",
    "                    description=description,\n",
    "                    online_enabled=False\n",
    "                )\n",
    "                fg.save(df)\n",
    "\n",
    "            logger.info(f\"Feature Group '{name}' created/updated successfully\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def create_feature_view(self, name: str, feature_group_name: str, features: list):\n",
    "        try:\n",
    "            fg = self.feature_store.get_feature_group(name=feature_group_name, version=1)\n",
    "            fv = self.feature_store.get_or_create_feature_view(\n",
    "                name=name,\n",
    "                version=1,\n",
    "                query=fg.select(features),\n",
    "                description=f\"Feature View for {name}\"\n",
    "            )\n",
    "            logger.info(f\"Feature View '{name}' created successfully\")\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def upload_file_safely(self, local_path: str, target_name: str):\n",
    "        \"\"\"\n",
    "        Upload file to Hopsworks dataset storage.\n",
    "        If it already exists, it will be overwritten.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.dataset_api.upload(\n",
    "                local_path,\n",
    "                f\"Resources/wattpredictor_artifacts/{target_name}\",\n",
    "                overwrite=True \n",
    "            )\n",
    "            logger.info(f\"Uploaded file to Feature Store: {target_name}\")\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def delete_file(self, target_name: str):\n",
    "        \"\"\"\n",
    "        Delete file from Hopsworks dataset storage.\n",
    "        Only use this if you want to clean up files manually.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            full_path = f\"Resources/wattpredictor_artifacts/{target_name}\"\n",
    "            self.dataset_api.delete(full_path)\n",
    "            logger.warning(f\"Deleted file from Feature Store: {target_name}\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"File not found or already deleted: {target_name}\")\n",
    "            # Not raising exception here to allow safe cleanup\n",
    "\n",
    "    def get_training_data(self, feature_view_name: str):\n",
    "        try:\n",
    "            fv = self.feature_store.get_feature_view(name=feature_view_name, version=1)\n",
    "            X, y = fv.training_data()\n",
    "            logger.info(f\"Retrieved training data from Feature View '{feature_view_name}'\")\n",
    "            return X, y\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42bdf4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "\n",
    "from WattPredictor.utils.helpers import create_directories, save_bin\n",
    "from WattPredictor.utils.exception import CustomException\n",
    "from WattPredictor import logger\n",
    "\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config, feature_store_config):\n",
    "        self.config = config\n",
    "        self.feature_store_config = feature_store_config\n",
    "        self.feature_store = FeatureStore(feature_store_config)\n",
    "\n",
    "    def check_status(self):\n",
    "        try:\n",
    "            with open(self.config.status_file, 'r') as f:\n",
    "                status_data = json.load(f)\n",
    "            return status_data.get(\"validation_status\", False)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Validation status error: {e}\")\n",
    "            return False\n",
    "\n",
    "    def basic_preprocessing(self):\n",
    "        try:\n",
    "            fg = self.feature_store.feature_store.get_feature_group(name=\"elec_wx_demand\", version=1)\n",
    "            df = fg.read()\n",
    "            df = df[['date', 'subba', 'value', 'temperature_2m']]\n",
    "\n",
    "            le = LabelEncoder()\n",
    "            df['sub_region_code'] = le.fit_transform(df['subba'])\n",
    "            df.rename(columns={'subba': 'sub_region', 'value': 'demand'}, inplace=True)\n",
    "            df = df[['date', 'sub_region_code', 'demand', 'temperature_2m']]\n",
    "\n",
    "            create_directories([os.path.dirname(self.config.label_encoder)])\n",
    "            save_bin(le, self.config.label_encoder)\n",
    "\n",
    "            self.feature_store.upload_file_safely(\n",
    "                self.config.label_encoder,\n",
    "                os.path.basename(self.config.label_encoder)\n",
    "            )\n",
    "\n",
    "            logger.info(\"Basic preprocessing complete.\")\n",
    "            return df\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def feature_engineering(self, df: pd.DataFrame):\n",
    "        try:\n",
    "            df['date'] = pd.to_datetime(df['date'], utc=True)\n",
    "            df['hour'] = df['date'].dt.hour\n",
    "            df['day_of_week'] = df['date'].dt.dayofweek\n",
    "            df['month'] = df['date'].dt.month\n",
    "            df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "            holidays = calendar().holidays(start=df['date'].min(), end=df['date'].max())\n",
    "            df['is_holiday'] = df['date'].isin(holidays).astype(int)\n",
    "\n",
    "            self.feature_store.create_feature_group(\n",
    "                name=\"elec_wx_features\",\n",
    "                df=df,\n",
    "                primary_key=[\"date\", \"sub_region_code\"],\n",
    "                event_time=\"date\",\n",
    "                description=\"Engineered features for electricity demand forecasting\"\n",
    "            )\n",
    "            logger.info(\"Feature engineering complete.\")\n",
    "            return df\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def transform(self):\n",
    "        if not self.check_status():\n",
    "            raise CustomException(\"Validation failed. Aborting transformation.\", sys)\n",
    "        try:\n",
    "            df = self.feature_engineering(self.basic_preprocessing())\n",
    "            df.sort_values(\"date\", inplace=True)\n",
    "\n",
    "            cutoff = pd.to_datetime(self.config.cutoff_date, utc=True)\n",
    "            train_df = df[df['date'] < cutoff].reset_index(drop=True)\n",
    "            test_df = df[df['date'] >= cutoff].reset_index(drop=True)\n",
    "            train_df.to_csv(self.config.train_features, index=False)\n",
    "            test_df.to_csv(self.config.test_features, index=False)\n",
    "\n",
    "            self.feature_store.upload_file_safely(self.config.train_features, \"train_df.csv\")\n",
    "            self.feature_store.upload_file_safely(self.config.test_features, \"test_df.csv\")\n",
    "\n",
    "            return train_df, test_df\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d60c4364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-11 14:48:38,210: INFO: helpers: yaml file: config_file\\config.yaml loaded successfully]\n",
      "[2025-07-11 14:48:38,215: INFO: helpers: yaml file: config_file\\params.yaml loaded successfully]\n",
      "[2025-07-11 14:48:38,219: INFO: helpers: yaml file: config_file\\schema.yaml loaded successfully]\n",
      "[2025-07-11 14:48:38,220: INFO: helpers: created directory at: artifacts]\n",
      "[2025-07-11 14:48:38,221: INFO: helpers: created directory at: artifacts/data_transformation]\n",
      "[2025-07-11 14:48:38,224: INFO: external: Initializing external client]\n",
      "[2025-07-11 14:48:38,225: INFO: external: Base URL: https://c.app.hopsworks.ai:443]\n",
      "[2025-07-11 14:48:40,955: INFO: python: Python Engine initialized.]\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1237149\n",
      "[2025-07-11 14:48:43,855: INFO: 385296184: Connected to Hopsworks Feature Store: JavithNaseem]\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (108.46s) \n",
      "[2025-07-11 14:50:36,039: INFO: helpers: created directory at: artifacts\\data_transformation]\n",
      "[2025-07-11 14:50:36,041: INFO: helpers: binary file saved at: artifacts\\data_transformation\\label_encoder.pkl]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92744419888b4c74ad3deab709076ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading f:\\WattPredictor\\artifacts\\data_transformation\\label_encoder.pkl: 0.000%|          | 0/549 elapsed<0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-11 14:50:39,044: INFO: 385296184: Uploaded file to Feature Store: label_encoder.pkl]\n",
      "[2025-07-11 14:50:39,047: INFO: 68799173: Basic preprocessing complete.]\n",
      "[2025-07-11 14:50:39,360: INFO: 385296184: Feature Group 'elec_wx_features' already exists. Inserting data instead.]\n",
      "[2025-07-11 14:50:39,361: INFO: 385296184: Feature Group 'elec_wx_features' does not exist. Creating new one.]\n",
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1237149/fs/1220685/fg/1495377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 39281/39281 | Elapsed Time: 00:07 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: elec_wx_features_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1237149/jobs/named/elec_wx_features_1_offline_fg_materialization/executions\n",
      "[2025-07-11 14:51:01,188: INFO: 385296184: Feature Group 'elec_wx_features' created/updated successfully]\n",
      "[2025-07-11 14:51:01,190: INFO: 68799173: Feature engineering complete.]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c000dfc96348d6ba21e97a726eedb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading f:\\WattPredictor\\artifacts\\data_transformation\\train_features.csv: 0.000%|          | 0/999134 elaps…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-11 14:51:06,177: INFO: 385296184: Uploaded file to Feature Store: train_df.csv]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2fec258a2e4934bd472e20fc5d6b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading f:\\WattPredictor\\artifacts\\data_transformation\\test_features.csv: 0.000%|          | 0/1025674 elaps…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-11 14:51:09,568: INFO: 385296184: Uploaded file to Feature Store: test_df.csv]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    feature_store_config = config.get_feature_store_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config,feature_store_config=feature_store_config)\n",
    "    train_df, test_df = data_transformation.transform()\n",
    "\n",
    "except Exception as e:\n",
    "    raise CustomException(str(e), sys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WattPredictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
