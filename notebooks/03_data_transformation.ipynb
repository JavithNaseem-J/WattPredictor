{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d21fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5a82b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b945b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(os.getcwd(), \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db4d2e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from WattPredictor.utils.helpers import *\n",
    "from WattPredictor.utils.exception import *\n",
    "from WattPredictor.constants import *\n",
    "from WattPredictor import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e87464eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_file: Path\n",
    "    status_file: str\n",
    "    label_encoder: Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class FeatureStoreConfig:\n",
    "    hopsworks_project_name: str\n",
    "    hopsworks_api_key: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04e5eb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath=CONFIG_PATH,\n",
    "                       params_filepath=PARAMS_PATH,\n",
    "                       schema_filepath=SCHEMA_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "        params = self.params.training\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            data_file=Path(config.data_file),\n",
    "            status_file=Path(config.status_file),\n",
    "            label_encoder=Path(config.label_encoder)\n",
    "        )\n",
    "\n",
    "        return data_transformation_config\n",
    "\n",
    "    def get_feature_store_config(self) -> FeatureStoreConfig:\n",
    "\n",
    "        config = self.config.feature_store\n",
    "\n",
    "        feature_store_config = FeatureStoreConfig(\n",
    "                hopsworks_project_name=config.hopsworks_project_name,\n",
    "                hopsworks_api_key=os.environ['hopsworks_api_key'],\n",
    "        )\n",
    "\n",
    "        return feature_store_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cf32f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from WattPredictor.config.feature_config import FeatureStoreConfig\n",
    "from WattPredictor.utils.exception import CustomException\n",
    "from WattPredictor import logger\n",
    "\n",
    "class FeatureStore:\n",
    "    def __init__(self, config:FeatureStoreConfig):\n",
    "        try:\n",
    "            self.config = config\n",
    "            self.connect()\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "\n",
    "    def connect(self):\n",
    "        try:\n",
    "            self.project = hopsworks.login(\n",
    "                project=self.config.hopsworks_project_name,\n",
    "                api_key_value=self.config.hopsworks_api_key\n",
    "            )\n",
    "            self.feature_store = self.project.get_feature_store()\n",
    "            self.dataset_api = self.project.get_dataset_api()\n",
    "            logger.info(f\"Connected to Hopsworks Feature Store: {self.config.hopsworks_project_name}\")\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "\n",
    "    def create_feature_group(self, name, df, primary_key, event_time, description, online_enabled=True, version=1):\n",
    "        try:\n",
    "            try:\n",
    "                fg = self.feature_store.get_feature_group(name=name, version=version)\n",
    "                logger.info(f\"Feature Group '{name}' v{version} exists. Deleting it.\")\n",
    "                fg.delete()\n",
    "            except Exception:\n",
    "                logger.info(f\"Feature Group '{name}' v{version} does not exist. Will create a new one.\")\n",
    "\n",
    "            # Create a new feature group\n",
    "            logger.info(f\"Creating Feature Group '{name}' v{version}.\")\n",
    "            fg = self.feature_store.get_or_create_feature_group(\n",
    "                name=name,\n",
    "                version=version,\n",
    "                primary_key=primary_key,\n",
    "                event_time=event_time,\n",
    "                description=description,\n",
    "                online_enabled=online_enabled\n",
    "            )\n",
    "\n",
    "            fg.save(df)\n",
    "            logger.info(f\"Feature Group '{name}' v{version} created and data inserted.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "\n",
    "\n",
    "    def create_feature_view(self, name: str, feature_group_name: str, features: list):\n",
    "        try:\n",
    "            fg = self.feature_store.get_feature_group(name=feature_group_name, version=1)\n",
    "            fv = self.feature_store.get_or_create_feature_view(\n",
    "                name=name,\n",
    "                version=1,\n",
    "                query=fg.select(features),\n",
    "                description=f\"Feature View for {name}\"\n",
    "            )\n",
    "            logger.info(f\"Feature View '{name}' created successfully\")\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "        \n",
    "\n",
    "    def save_training_dataset(self, feature_view_name, version_description, output_format=\"csv\"):\n",
    "        try:\n",
    "            fv = self.feature_store.get_feature_view(name=feature_view_name, version=1)\n",
    "            td = fv.create_training_data(\n",
    "                description=version_description,\n",
    "                data_format=output_format,\n",
    "                write_options={\"wait_for_job\": True}\n",
    "            )\n",
    "            logger.info(f\"Training dataset created for Feature View '{feature_view_name}'.\")\n",
    "            return td\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "        \n",
    "    def load_latest_training_dataset(self, feature_view_name):\n",
    "        try:\n",
    "            fv = self.feature_store.get_feature_view(name=feature_view_name, version=1)\n",
    "            return fv.training_data()\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "\n",
    "    def upload_file_safely(self, local_path: str, target_name: str):\n",
    "\n",
    "        try:\n",
    "            self.dataset_api.upload(\n",
    "                local_path,\n",
    "                f\"Resources/wattpredictor_artifacts/{target_name}\",\n",
    "                overwrite=True \n",
    "            )\n",
    "            logger.info(f\"Uploaded file to Feature Store: {target_name}\")\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "\n",
    "    def get_training_data(self, feature_view_name: str):\n",
    "        try:\n",
    "            fv = self.feature_store.get_feature_view(name=feature_view_name, version=1)\n",
    "            X, y = fv.training_data()\n",
    "            logger.info(f\"Retrieved training data from Feature View '{feature_view_name}'\")\n",
    "            return X, y\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "    \n",
    "    \n",
    "    def get_online_features(self, feature_view_name, key_dict: dict, version=1):\n",
    "        try:\n",
    "            fv = self.feature_store.get_feature_view(name=feature_view_name, version=version)\n",
    "            if fv is None:\n",
    "                logger.error(f\"[Online Fetch] Feature View '{feature_view_name}' v{version} not found.\")\n",
    "                raise CustomException(f\"Feature View '{feature_view_name}' v{version} is None\", sys)\n",
    "\n",
    "            expected_primary_keys = [\"date_str\", \"sub_region_code\"]\n",
    "            \n",
    "            key_values = [key_dict[key] for key in expected_primary_keys]\n",
    "            \n",
    "            try:\n",
    "                result = fv.get_feature_vector(key_dict)\n",
    "                logger.info(f\"[Online Fetch] Fetched online features using get_feature_vector for {key_dict}: {result}\")\n",
    "                return result\n",
    "            except Exception as vector_error:\n",
    "                logger.warning(f\"get_feature_vector failed: {vector_error}, trying get_serving_vector\")\n",
    "                \n",
    "                result = fv.get_serving_vector(key_values).to_dict()\n",
    "                logger.info(f\"[Online Fetch] Fetched online features using get_serving_vector for {key_dict}: {result}\")\n",
    "                return result\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[Online Fetch] Failed to fetch online features for {feature_view_name} with key {key_dict}\")\n",
    "            raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42bdf4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "from WattPredictor.utils.helpers import create_directories, save_bin\n",
    "from WattPredictor.utils.exception import CustomException\n",
    "from WattPredictor import logger\n",
    "\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig, feature_store_config: FeatureStoreConfig):\n",
    "        self.config = config\n",
    "        self.feature_store = FeatureStore(feature_store_config)\n",
    "\n",
    "    def check_status(self):\n",
    "        try:\n",
    "            with open(self.config.status_file, 'r') as f:\n",
    "                status_data = json.load(f)\n",
    "            return status_data.get(\"validation_status\", False)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Validation status check failed: {e}\")\n",
    "            return False\n",
    "\n",
    "    def basic_preprocessing(self) -> pd.DataFrame:\n",
    "        try:\n",
    "            fg = self.feature_store.feature_store.get_feature_group(name=\"elec_wx_demand\", version=1)\n",
    "            df = fg.read()\n",
    "            le = LabelEncoder()\n",
    "            df['sub_region_code'] = le.fit_transform(df['subba'])\n",
    "            df.rename(columns={'subba': 'sub_region', 'value': 'demand'}, inplace=True)\n",
    "            df = df[['date_str','date', 'sub_region_code', 'demand', 'temperature_2m']]\n",
    "\n",
    "            create_directories([os.path.dirname(self.config.label_encoder)])\n",
    "            save_bin(le, self.config.label_encoder)\n",
    "            self.feature_store.upload_file_safely(self.config.label_encoder, \"label_encoder.pkl\")\n",
    "\n",
    "            logger.info(\"Label encoding and preprocessing complete.\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def feature_engineering(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        try:\n",
    "            df['date'] = pd.to_datetime(df['date'], utc=True)\n",
    "            \n",
    "            df['hour'] = df['date'].dt.hour\n",
    "            df['day_of_week'] = df['date'].dt.dayofweek\n",
    "            df['month'] = df['date'].dt.month\n",
    "            df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "            holidays = calendar().holidays(start=df['date'].min(), end=df['date'].max())\n",
    "            df['is_holiday'] = df['date'].isin(holidays).astype(int)\n",
    "\n",
    "            \n",
    "            self.feature_store.create_feature_group(\n",
    "                name=\"elec_wx_features\",\n",
    "                df=df,\n",
    "                primary_key=[\"date_str\",\"sub_region_code\"],\n",
    "                event_time=\"date\",\n",
    "                description=\"Engineered electricity demand features\",\n",
    "                online_enabled=True\n",
    "            )\n",
    "\n",
    "            logger.info(\"Feature group created and feature engineering complete.\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def transform(self):\n",
    "        if not self.check_status():\n",
    "            raise CustomException(\"Validation failed. Aborting transformation.\", sys)\n",
    "        try:\n",
    "            df = self.feature_engineering(self.basic_preprocessing())\n",
    "            df.sort_values(\"date\", inplace=True)\n",
    "\n",
    "            self.feature_store.create_feature_view(\n",
    "                name=\"elec_wx_features_view\",\n",
    "                feature_group_name=\"elec_wx_features\",\n",
    "                features=[\n",
    "                    \"date\", \"sub_region_code\", \"demand\", \"temperature_2m\",\n",
    "                    \"hour\", \"day_of_week\", \"month\", \"is_weekend\", \"is_holiday\"\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            self.feature_store.save_training_dataset(\n",
    "                feature_view_name=\"elec_wx_features_view\",\n",
    "                version_description=\"initial training dataset with all features\",\n",
    "                output_format=\"csv\"\n",
    "            )\n",
    "\n",
    "            logger.info(\"Feature view + training dataset saved successfully.\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d60c4364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-15 14:55:48,106: INFO: helpers: yaml file: config_file\\config.yaml loaded successfully]\n",
      "[2025-07-15 14:55:48,124: INFO: helpers: yaml file: config_file\\params.yaml loaded successfully]\n",
      "[2025-07-15 14:55:48,124: INFO: helpers: yaml file: config_file\\schema.yaml loaded successfully]\n",
      "[2025-07-15 14:55:48,124: INFO: helpers: created directory at: artifacts]\n",
      "[2025-07-15 14:55:48,124: INFO: helpers: created directory at: artifacts/data_transformation]\n",
      "[2025-07-15 14:55:48,132: INFO: external: Initializing external client]\n",
      "[2025-07-15 14:55:48,132: INFO: external: Base URL: https://c.app.hopsworks.ai:443]\n",
      "[2025-07-15 14:55:50,923: INFO: python: Python Engine initialized.]\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1240214\n",
      "[2025-07-15 14:55:53,557: INFO: 3903490710: Connected to Hopsworks Feature Store: WattPredictor]\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (3.91s) \n",
      "[2025-07-15 14:56:00,842: INFO: helpers: created directory at: artifacts\\data_transformation]\n",
      "[2025-07-15 14:56:00,842: INFO: helpers: binary file saved at: artifacts\\data_transformation\\label_encoder.pkl]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb059518d964f4193454641f28af70b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading f:\\WattPredictor\\artifacts\\data_transformation\\label_encoder.pkl: 0.000%|          | 0/549 elapsed<0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-15 14:56:03,477: INFO: 3903490710: Uploaded file to Feature Store: label_encoder.pkl]\n",
      "[2025-07-15 14:56:03,479: INFO: 4102113803: Label encoding and preprocessing complete.]\n",
      "[2025-07-15 14:56:03,991: INFO: 3903490710: Feature Group 'elec_wx_features' v1 exists. Deleting it.]\n",
      "[2025-07-15 14:56:03,991: WARNING: warnings: JobWarning: All jobs associated to feature group `elec_wx_features`, version `1` will be removed.\n",
      "]\n",
      "[2025-07-15 14:56:05,208: INFO: 3903490710: Creating Feature Group 'elec_wx_features' v1.]\n",
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1240214/fs/1223749/fg/1495468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 39545/39545 | Elapsed Time: 00:04 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: elec_wx_features_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1240214/jobs/named/elec_wx_features_1_offline_fg_materialization/executions\n",
      "[2025-07-15 14:56:27,682: INFO: 3903490710: Feature Group 'elec_wx_features' v1 created and data inserted.]\n",
      "[2025-07-15 14:56:27,683: INFO: 4102113803: Feature group created and feature engineering complete.]\n"
     ]
    },
    {
     "ename": "CustomException",
     "evalue": "Exception in C:\\Users\\Javith Naseem\\AppData\\Local\\Temp\\ipykernel_9664\\1019222407.py, line 6: Exception in C:\\Users\\Javith Naseem\\AppData\\Local\\Temp\\ipykernel_9664\\4102113803.py, line 82: Exception in C:\\Users\\Javith Naseem\\AppData\\Local\\Temp\\ipykernel_9664\\3903490710.py, line 62: Cannot get back the feature view because the query defined is no longer valid. Some feature groups used in the query may have been deleted. You can clean up this feature view on the UI or `FeatureView.clean`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRestAPIError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mf:\\Program Files\\anaconda\\envs\\WattPredictor\\lib\\site-packages\\hsfs\\core\\feature_view_api.py:145\u001b[0m, in \u001b[0;36mFeatureViewApi.get_by_name_version\u001b[1;34m(self, name, version)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m feature_view\u001b[38;5;241m.\u001b[39mFeatureView\u001b[38;5;241m.\u001b[39mfrom_response_json(\n\u001b[1;32m--> 145\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_GET\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexpand\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransformationfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m     )\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RestAPIError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mf:\\Program Files\\anaconda\\envs\\WattPredictor\\lib\\site-packages\\hopsworks_common\\decorators.py:48\u001b[0m, in \u001b[0;36mconnected.<locals>.if_connected\u001b[1;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(inst, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\Program Files\\anaconda\\envs\\WattPredictor\\lib\\site-packages\\hopsworks_common\\client\\base.py:186\u001b[0m, in \u001b[0;36mClient._send_request\u001b[1;34m(self, method, path_params, query_params, headers, data, stream, files, with_base_path_params)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mRestAPIError(url, response)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n",
      "\u001b[1;31mRestAPIError\u001b[0m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1240214/featurestores/1223749/featureview/elec_wx_features_view/version/1). Server response: \nHTTP code: 404, HTTP reason: Not Found, body: b'{\"errorCode\":270009,\"usrMsg\":\"Cannot construct the query. Parent feature groups of the following features are not available anymore: date, sub_region_code, demand, temperature_2m, hour, day_of_week, month, is_weekend, is_holiday\",\"errorMsg\":\"Featuregroup wasn\\'t found.\"}', error code: 270009, error msg: Featuregroup wasn't found., user msg: Cannot construct the query. Parent feature groups of the following features are not available anymore: date, sub_region_code, demand, temperature_2m, hour, day_of_week, month, is_weekend, is_holiday",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 62\u001b[0m, in \u001b[0;36mFeatureStore.create_feature_view\u001b[1;34m(self, name, feature_group_name, features)\u001b[0m\n\u001b[0;32m     61\u001b[0m fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_store\u001b[38;5;241m.\u001b[39mget_feature_group(name\u001b[38;5;241m=\u001b[39mfeature_group_name, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 62\u001b[0m fv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_or_create_feature_view\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFeature View for \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     67\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature View \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m created successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mf:\\Program Files\\anaconda\\envs\\WattPredictor\\lib\\site-packages\\hopsworks_common\\usage.py:246\u001b[0m, in \u001b[0;36mmethod_logger.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    245\u001b[0m     exception \u001b[38;5;241m=\u001b[39m e\n\u001b[1;32m--> 246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mf:\\Program Files\\anaconda\\envs\\WattPredictor\\lib\\site-packages\\hopsworks_common\\usage.py:242\u001b[0m, in \u001b[0;36mmethod_logger.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m# Call the original method\u001b[39;00m\n\u001b[1;32m--> 242\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mf:\\Program Files\\anaconda\\envs\\WattPredictor\\lib\\site-packages\\hsfs\\feature_store.py:1732\u001b[0m, in \u001b[0;36mFeatureStore.get_or_create_feature_view\u001b[1;34m(self, name, query, version, description, labels, inference_helper_columns, training_helper_columns, transformation_functions, logging_enabled)\u001b[0m\n\u001b[0;32m   1680\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get feature view metadata object or create a new one if it doesn't exist. This method doesn't update\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m \u001b[38;5;124;03mexisting feature view metadata object.\u001b[39;00m\n\u001b[0;32m   1682\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1730\u001b[0m \u001b[38;5;124;03m    `FeatureView`: The feature view metadata object.\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1732\u001b[0m fv_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_view_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fv_object:\n",
      "File \u001b[1;32mf:\\Program Files\\anaconda\\envs\\WattPredictor\\lib\\site-packages\\hsfs\\core\\feature_view_engine.py:186\u001b[0m, in \u001b[0;36mFeatureViewEngine.get\u001b[1;34m(self, name, version)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version:\n\u001b[1;32m--> 186\u001b[0m     fv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_view_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_by_name_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mf:\\Program Files\\anaconda\\envs\\WattPredictor\\lib\\site-packages\\hopsworks_common\\decorators.py:67\u001b[0m, in \u001b[0;36mcatch_not_found.<locals>.decorator.<locals>.g\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RestAPIError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mf:\\Program Files\\anaconda\\envs\\WattPredictor\\lib\\site-packages\\hsfs\\core\\feature_view_api.py:153\u001b[0m, in \u001b[0;36mFeatureViewApi.get_by_name_version\u001b[1;34m(self, name, version)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mjson()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m270009\u001b[39m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get back the feature view because the query defined is no longer valid.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Some feature groups used in the query may have been deleted. You can clean up this feature view on the UI\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or `FeatureView.clean`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot get back the feature view because the query defined is no longer valid. Some feature groups used in the query may have been deleted. You can clean up this feature view on the UI or `FeatureView.clean`.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCustomException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 82\u001b[0m, in \u001b[0;36mDataTransformation.transform\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     80\u001b[0m df\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_feature_view\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43melec_wx_features_view\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_group_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43melec_wx_features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msub_region_code\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdemand\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature_2m\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhour\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mday_of_week\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmonth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mis_weekend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mis_holiday\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_store\u001b[38;5;241m.\u001b[39msave_training_dataset(\n\u001b[0;32m     92\u001b[0m     feature_view_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melec_wx_features_view\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     93\u001b[0m     version_description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial training dataset with all features\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     94\u001b[0m     output_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m )\n",
      "Cell \u001b[1;32mIn[7], line 70\u001b[0m, in \u001b[0;36mFeatureStore.create_feature_view\u001b[1;34m(self, name, feature_group_name, features)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CustomException(e, sys)\n",
      "\u001b[1;31mCustomException\u001b[0m: Exception in C:\\Users\\Javith Naseem\\AppData\\Local\\Temp\\ipykernel_9664\\3903490710.py, line 62: Cannot get back the feature view because the query defined is no longer valid. Some feature groups used in the query may have been deleted. You can clean up this feature view on the UI or `FeatureView.clean`.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCustomException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      5\u001b[0m         data_transformation \u001b[38;5;241m=\u001b[39m DataTransformation(config\u001b[38;5;241m=\u001b[39mdata_transformation_config,feature_store_config\u001b[38;5;241m=\u001b[39mfeature_store_config)\n\u001b[1;32m----> 6\u001b[0m         df\u001b[38;5;241m=\u001b[39m \u001b[43mdata_transformation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[8], line 100\u001b[0m, in \u001b[0;36mDataTransformation.transform\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CustomException(e, sys)\n",
      "\u001b[1;31mCustomException\u001b[0m: Exception in C:\\Users\\Javith Naseem\\AppData\\Local\\Temp\\ipykernel_9664\\4102113803.py, line 82: Exception in C:\\Users\\Javith Naseem\\AppData\\Local\\Temp\\ipykernel_9664\\3903490710.py, line 62: Cannot get back the feature view because the query defined is no longer valid. Some feature groups used in the query may have been deleted. You can clean up this feature view on the UI or `FeatureView.clean`.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCustomException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m         df\u001b[38;5;241m=\u001b[39m data_transformation\u001b[38;5;241m.\u001b[39mtransform()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m----> 9\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CustomException(\u001b[38;5;28mstr\u001b[39m(e), sys)\n",
      "\u001b[1;31mCustomException\u001b[0m: Exception in C:\\Users\\Javith Naseem\\AppData\\Local\\Temp\\ipykernel_9664\\1019222407.py, line 6: Exception in C:\\Users\\Javith Naseem\\AppData\\Local\\Temp\\ipykernel_9664\\4102113803.py, line 82: Exception in C:\\Users\\Javith Naseem\\AppData\\Local\\Temp\\ipykernel_9664\\3903490710.py, line 62: Cannot get back the feature view because the query defined is no longer valid. Some feature groups used in the query may have been deleted. You can clean up this feature view on the UI or `FeatureView.clean`."
     ]
    }
   ],
   "source": [
    "try:\n",
    "        config = ConfigurationManager()\n",
    "        data_transformation_config = config.get_data_transformation_config()\n",
    "        feature_store_config = config.get_feature_store_config()\n",
    "        data_transformation = DataTransformation(config=data_transformation_config,feature_store_config=feature_store_config)\n",
    "        df= data_transformation.transform()\n",
    "\n",
    "except Exception as e:\n",
    "        raise CustomException(str(e), sys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WattPredictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
