{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb3ef160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "sys.path.append(os.path.join(os.getcwd(), \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1045c0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from WattPredictor.utils.helpers import *\n",
    "from WattPredictor.utils.exception import *\n",
    "from WattPredictor.constants import *\n",
    "from WattPredictor.utils.logging import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "519f8add",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataDriftConfig:\n",
    "    baseline_start: str\n",
    "    baseline_end: str\n",
    "    current_start: str\n",
    "    current_end: str\n",
    "    report_dir: Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class FeatureStoreConfig:\n",
    "    hopsworks_project_name: str\n",
    "    hopsworks_api_key: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05121324",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "\n",
    "    def __init__(self, config_filepath=CONFIG_PATH,\n",
    "                       params_filepath=PARAMS_PATH,\n",
    "                       schema_filepath=SCHEMA_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_drift_config(self) -> DataDriftConfig:\n",
    "        config = self.config.data_drift\n",
    "        params = self.params.drift\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        data_drift_cofig =  DataDriftConfig(\n",
    "            baseline_start=self.params.drift.baseline_start,\n",
    "            baseline_end=self.params.drift.baseline_end,\n",
    "            current_start=self.params.drift.current_start,\n",
    "            current_end=self.params.drift.current_end,\n",
    "            report_dir=Path(config.report_dir)\n",
    "        )\n",
    "        \n",
    "        return data_drift_cofig\n",
    "    \n",
    "\n",
    "    def get_feature_store_config(self) -> FeatureStoreConfig:\n",
    "        config = self.config.feature_store\n",
    "\n",
    "        feature_store_config = FeatureStoreConfig(\n",
    "                hopsworks_project_name=config.hopsworks_project_name,\n",
    "                hopsworks_api_key=os.environ['hopsworks_api_key'],\n",
    "        )\n",
    "\n",
    "        return feature_store_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6637cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from WattPredictor.utils.exception import CustomException\n",
    "\n",
    "class FeatureStore:\n",
    "    def __init__(self, config):\n",
    "        try:\n",
    "            self.config = config\n",
    "            self.connect()\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "\n",
    "    def connect(self):\n",
    "        try:\n",
    "            self.project = hopsworks.login(\n",
    "                project=self.config.hopsworks_project_name,\n",
    "                api_key_value=self.config.hopsworks_api_key\n",
    "            )\n",
    "            self.feature_store = self.project.get_feature_store()\n",
    "            self.dataset_api = self.project.get_dataset_api()\n",
    "            logger.info(f\"Connected to Hopsworks Feature Store: {self.config.hopsworks_project_name}\")\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "\n",
    "    def create_feature_group(self, name, df, primary_key, event_time, description, online_enabled=True, version=1):\n",
    "        try:\n",
    "            # Check if the feature group already exists\n",
    "            try:\n",
    "                fg = self.feature_store.get_feature_group(name=name, version=version)\n",
    "                logger.info(f\"Feature Group '{name}' v{version} exists. Deleting it.\")\n",
    "                fg.delete()  # Delete existing feature group\n",
    "            except Exception:\n",
    "                logger.info(f\"Feature Group '{name}' v{version} does not exist. Will create a new one.\")\n",
    "\n",
    "            # Create a new feature group\n",
    "            logger.info(f\"Creating Feature Group '{name}' v{version}.\")\n",
    "            fg = self.feature_store.get_or_create_feature_group(\n",
    "                name=name,\n",
    "                version=version,\n",
    "                primary_key=primary_key,\n",
    "                event_time=event_time,\n",
    "                description=description,\n",
    "                online_enabled=online_enabled\n",
    "            )\n",
    "\n",
    "            fg.save(df)\n",
    "            logger.info(f\"Feature Group '{name}' v{version} created and data inserted.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "\n",
    "\n",
    "    def create_feature_view(self, name: str, feature_group_name: str, features: list):\n",
    "        try:\n",
    "            fg = self.feature_store.get_feature_group(name=feature_group_name, version=1)\n",
    "            fv = self.feature_store.get_or_create_feature_view(\n",
    "                name=name,\n",
    "                version=1,\n",
    "                query=fg.select(features),\n",
    "                description=f\"Feature View for {name}\"\n",
    "            )\n",
    "            logger.info(f\"Feature View '{name}' created successfully\")\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "        \n",
    "\n",
    "    def save_training_dataset(self, feature_view_name, version_description, output_format=\"csv\"):\n",
    "        try:\n",
    "            fv = self.feature_store.get_feature_view(name=feature_view_name, version=1)\n",
    "            td = fv.create_training_data(\n",
    "                description=version_description,\n",
    "                data_format=output_format,\n",
    "                write_options={\"wait_for_job\": True}\n",
    "            )\n",
    "            logger.info(f\"Training dataset created for Feature View '{feature_view_name}'.\")\n",
    "            return td\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "        \n",
    "    def load_latest_training_dataset(self, feature_view_name):\n",
    "        try:\n",
    "            fv = self.feature_store.get_feature_view(name=feature_view_name, version=1)\n",
    "            return fv.training_data()\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "\n",
    "    def upload_file_safely(self, local_path: str, target_name: str):\n",
    "\n",
    "        try:\n",
    "            self.dataset_api.upload(\n",
    "                local_path,\n",
    "                f\"Resources/wattpredictor_artifacts/{target_name}\",\n",
    "                overwrite=True \n",
    "            )\n",
    "            logger.info(f\"Uploaded file to Feature Store: {target_name}\")\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "\n",
    "    def get_training_data(self, feature_view_name: str):\n",
    "        try:\n",
    "            fv = self.feature_store.get_feature_view(name=feature_view_name, version=1)\n",
    "            X, y = fv.training_data()\n",
    "            logger.info(f\"Retrieved training data from Feature View '{feature_view_name}'\")\n",
    "            return X, y\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "    \n",
    "    \n",
    "    def get_online_features(self, feature_view_name, key_dict: dict, version=1):\n",
    "        try:\n",
    "            fv = self.feature_store.get_feature_view(name=feature_view_name, version=version)\n",
    "            if fv is None:\n",
    "                logger.error(f\"[Online Fetch] Feature View '{feature_view_name}' v{version} not found.\")\n",
    "                raise CustomException(f\"Feature View '{feature_view_name}' v{version} is None\", sys)\n",
    "\n",
    "            expected_primary_keys = [\"date_str\", \"sub_region_code\"]\n",
    "            \n",
    "            key_values = [key_dict[key] for key in expected_primary_keys]\n",
    "            \n",
    "            try:\n",
    "                result = fv.get_feature_vector(key_dict)\n",
    "                logger.info(f\"[Online Fetch] Fetched online features using get_feature_vector for {key_dict}: {result}\")\n",
    "                return result\n",
    "            except Exception as vector_error:\n",
    "                logger.warning(f\"get_feature_vector failed: {vector_error}, trying get_serving_vector\")\n",
    "                \n",
    "                result = fv.get_serving_vector(key_values).to_dict()\n",
    "                logger.info(f\"[Online Fetch] Fetched online features using get_serving_vector for {key_dict}: {result}\")\n",
    "                return result\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[Online Fetch] Failed to fetch online features for {feature_view_name} with key {key_dict}\")\n",
    "            raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d68bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-16 10:27:24,882: WARNING: warnings: DeprecationWarning: Please use `LinAlgError` from the `scipy.linalg` namespace, the `scipy.linalg.basic` namespace is deprecated.\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from evidently import ColumnMapping\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "from evidently.metrics import DatasetDriftMetric, ColumnDriftMetric, ColumnSummaryMetric\n",
    "from WattPredictor.utils.helpers import create_directories\n",
    "from WattPredictor.utils.exception import CustomException\n",
    "\n",
    "\n",
    "class DriftDetector:\n",
    "    def __init__(self, feature_store_config, config):\n",
    "        self.config = config\n",
    "        self.feature_store = FeatureStore(feature_store_config)\n",
    "\n",
    "    def _load_data(self, start_date, end_date):\n",
    "        try:\n",
    "            df, _ = self.feature_store.load_latest_training_dataset('elec_wx_features_view')\n",
    "            df['date'] = pd.to_datetime(df['date'], utc=True)\n",
    "            df = df[(df['date'] >= start_date) & (df['date'] <= end_date)]\n",
    "            df = df.drop(columns=[\"date_str\"], errors=\"ignore\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            raise CustomException(f\"Error loading data from Hopsworks: {e}\", sys)\n",
    "\n",
    "    def Detect(self):\n",
    "        try:\n",
    "            baseline_df = self._load_data(self.config.baseline_start, self.config.baseline_end)\n",
    "            current_df = self._load_data(self.config.current_start, self.config.current_end)\n",
    "\n",
    "            if baseline_df.empty or current_df.empty:\n",
    "                raise CustomException(\"Baseline or current data is empty\", sys)\n",
    "\n",
    "            # Create column mapping for better drift detection\n",
    "            column_mapping = ColumnMapping()\n",
    "            \n",
    "            # Set target column if it exists\n",
    "            if 'demand' in baseline_df.columns:\n",
    "                column_mapping.target = 'demand'\n",
    "            \n",
    "            # Set prediction column if it exists\n",
    "            if 'prediction' in current_df.columns:\n",
    "                column_mapping.prediction = 'prediction'\n",
    "\n",
    "            # Create metrics list\n",
    "            metrics = [\n",
    "                DataDriftPreset(),\n",
    "                DatasetDriftMetric(),\n",
    "                ColumnSummaryMetric(column_name=\"demand\"),\n",
    "            ]\n",
    "            \n",
    "            # Add column drift metrics for specific columns if they exist\n",
    "            if \"temperature_2m\" in baseline_df.columns:\n",
    "                metrics.append(ColumnDriftMetric(column_name=\"temperature_2m\"))\n",
    "            \n",
    "            if \"sub_region_code\" in baseline_df.columns:\n",
    "                metrics.append(ColumnDriftMetric(column_name=\"sub_region_code\"))\n",
    "\n",
    "            # Create and run report\n",
    "            report = Report(metrics=metrics)\n",
    "            report.run(reference_data=baseline_df, current_data=current_df, column_mapping=column_mapping)\n",
    "            \n",
    "            # Create directories and save reports\n",
    "            create_directories([self.config.report_dir])\n",
    "            html_path = self.config.report_dir / \"drift_report.html\"\n",
    "            json_path = self.config.report_dir / \"drift_report.json\"\n",
    "\n",
    "            report.save_html(str(html_path))\n",
    "            report_dict = report.as_dict()\n",
    "\n",
    "            def json_serializer(obj):\n",
    "                if hasattr(obj, 'isoformat'):\n",
    "                    return obj.isoformat()\n",
    "                elif hasattr(obj, 'tolist'):\n",
    "                    return obj.tolist()\n",
    "                elif hasattr(obj, '__dict__'):\n",
    "                    return obj.__dict__\n",
    "                elif pd.isna(obj):\n",
    "                    return None\n",
    "                else:\n",
    "                    return str(obj)\n",
    "\n",
    "            with open(json_path, \"w\") as f:\n",
    "                json.dump(report_dict, f, indent=4, default=json_serializer)\n",
    "\n",
    "            # Extract drift detection result\n",
    "            drift_detected = False\n",
    "            try:\n",
    "                # Look for dataset drift in the metrics results\n",
    "                for metric in report_dict.get('metrics', []):\n",
    "                    if metric.get('metric') == 'DatasetDriftMetric':\n",
    "                        drift_detected = metric.get('result', {}).get('dataset_drift', False)\n",
    "                        break\n",
    "                    elif 'dataset_drift' in metric.get('result', {}):\n",
    "                        drift_detected = metric['result']['dataset_drift']\n",
    "                        break\n",
    "            except (KeyError, TypeError) as e:\n",
    "                logger.warning(f\"Could not extract drift detection result: {e}\")\n",
    "\n",
    "            logger.info(f\"Drift Detected: {drift_detected}\")\n",
    "            logger.info(f\"Report saved at {html_path}\")\n",
    "            return drift_detected, report_dict\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(f\"Drift detection failed: {e}\", sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad5ac3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-16 10:27:33,769: INFO: helpers: yaml file: config_file\\config.yaml loaded successfully]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-16 10:27:33,785: INFO: helpers: yaml file: config_file\\params.yaml loaded successfully]\n",
      "[2025-07-16 10:27:33,800: INFO: helpers: yaml file: config_file\\schema.yaml loaded successfully]\n",
      "[2025-07-16 10:27:33,803: INFO: helpers: created directory at: artifacts]\n",
      "[2025-07-16 10:27:33,805: INFO: helpers: created directory at: artifacts/data_drift]\n",
      "[2025-07-16 10:27:33,810: INFO: external: Initializing external client]\n",
      "[2025-07-16 10:27:33,810: INFO: external: Base URL: https://c.app.hopsworks.ai:443]\n",
      "[2025-07-16 10:27:36,286: WARNING: warnings: UserWarning: The installed hopsworks client version 4.3.1 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-16 10:27:41,459: INFO: python: Python Engine initialized.]\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1240214\n",
      "[2025-07-16 10:27:43,438: INFO: 909816121: Connected to Hopsworks Feature Store: WattPredictor]\n"
     ]
    },
    {
     "ename": "CustomException",
     "evalue": "Exception in C:\\Users\\Javith Naseem\\AppData\\Local\\Temp\\ipykernel_1648\\768199110.py, line 6: 'DriftDetector' object has no attribute 'Detect'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      5\u001b[0m     drift_detector \u001b[38;5;241m=\u001b[39m DriftDetector(config\u001b[38;5;241m=\u001b[39mdrift_config, feature_store_config\u001b[38;5;241m=\u001b[39mfeature_store_config)\n\u001b[1;32m----> 6\u001b[0m     drift_detected, report_dict \u001b[38;5;241m=\u001b[39m \u001b[43mdrift_detector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDetect\u001b[49m()        \n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DriftDetector' object has no attribute 'Detect'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCustomException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m     drift_detected, report_dict \u001b[38;5;241m=\u001b[39m drift_detector\u001b[38;5;241m.\u001b[39mDetect()        \n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CustomException(e, sys)\n",
      "\u001b[1;31mCustomException\u001b[0m: Exception in C:\\Users\\Javith Naseem\\AppData\\Local\\Temp\\ipykernel_1648\\768199110.py, line 6: 'DriftDetector' object has no attribute 'Detect'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    drift_config = config.get_data_drift_config()\n",
    "    feature_store_config = config.get_feature_store_config()\n",
    "    drift_detector = DriftDetector(config=drift_config, feature_store_config=feature_store_config)\n",
    "    drift_detected, report_dict = drift_detector.Detect()        \n",
    "        \n",
    "except Exception as e:\n",
    "    raise CustomException(e, sys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WattPredictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
