{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d86ad127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eb815bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'WattPredictor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mWattPredictor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mWattPredictor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mWattPredictor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'WattPredictor'"
     ]
    }
   ],
   "source": [
    "from WattPredictor.utils.helpers import *\n",
    "from WattPredictor.constants import *\n",
    "from WattPredictor.utils.exception import *\n",
    "from WattPredictor import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f36232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1502661",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    elec_api: str\n",
    "    wx_api: str\n",
    "    elec_raw_data: Path\n",
    "    wx_raw_data: Path\n",
    "    data_file: Path\n",
    "    start_date: str\n",
    "    end_date: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18859201",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, \n",
    "                 config_filepath=CONFIG_PATH,\n",
    "                 params_filepath=PARAMS_PATH,\n",
    "                 schema_filepath=SCHEMA_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        if schema_filepath.exists():\n",
    "            self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        config = self.config.data_ingestion\n",
    "        params = self.params.dates\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            elec_api=config.elec_api,\n",
    "            wx_api=config.wx_api,\n",
    "            elec_raw_data=Path(config.elec_raw_data),\n",
    "            wx_raw_data=Path(config.wx_raw_data),\n",
    "            data_file=Path(config.data_file),\n",
    "            start_date=params.start_date,\n",
    "            end_date=params.end_date\n",
    "        )\n",
    "\n",
    "        return data_ingestion_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d7e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "from retry_requests import retry\n",
    "from electron import logger\n",
    "from pathlib import Path\n",
    "\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after=3600)\n",
    "retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.openmeteo = openmeteo_requests.Client(session=retry_session)\n",
    "\n",
    "    def _elec_get_api_url(self, year, month, day):\n",
    "        return self.config.elec_api, {\n",
    "            \"frequency\": \"hourly\",\n",
    "            \"data[0]\": \"value\",\n",
    "            \"sort[0][column]\": \"period\", \n",
    "            \"sort[0][direction]\": \"desc\",\n",
    "            \"facets[parent][0]\": \"NYIS\",\n",
    "            \"offset\": 0, \n",
    "            \"length\": 5000,\n",
    "            \"start\": f\"{year}-{month:02d}-{day:02d}\",\n",
    "            \"end\": (datetime(year, month, day) + timedelta(days=1)).strftime(\"%Y-%m-%d\"),\n",
    "            \"api_key\": 'dqRq8VpXSoyUrCbrPhuYFxGl6Rul9kmVcRshZ98c'\n",
    "        }\n",
    "\n",
    "    def _wx_get_api_url(self, start_date, end_date):\n",
    "        return self.config.wx_api, {\n",
    "            \"latitude\": 40.7128,\n",
    "            \"longitude\": -74.0060,\n",
    "            \"start_date\": start_date.strftime(\"%Y-%m-%d\"),\n",
    "            \"end_date\": end_date.strftime(\"%Y-%m-%d\"),\n",
    "            \"hourly\": [\"temperature_2m\", \"weather_code\",\n",
    "            \"relative_humidity_2m\", \"wind_speed_10m\"],\n",
    "            \"timeformat\": \"unixtime\",\n",
    "            \"timezone\": \"America/New_York\"\n",
    "        }\n",
    "\n",
    "    def _fetch_data(self, data_type, *args):\n",
    "        \"\"\"Generic fetch method for both electricity and weather data\"\"\"\n",
    "        try:\n",
    "            if data_type == \"electricity\":\n",
    "                year, month, day = args\n",
    "                url, params = self._elec_get_api_url(year, month, day)\n",
    "                response = requests.get(url, params=params)\n",
    "                response.raise_for_status()\n",
    "                data = response.json()\n",
    "                \n",
    "                create_directories([self.config.elec_raw_data])\n",
    "                file_path = self.config.elec_raw_data / f\"hourly_demand_{year}-{month:02d}-{day:02d}.json\"\n",
    "                save_json(file_path, data)\n",
    "                \n",
    "                # Load and return DataFrame\n",
    "                if 'response' in data and 'data' in data['response']:\n",
    "                    return pd.DataFrame(data['response']['data'])\n",
    "                \n",
    "            elif data_type == \"weather\":\n",
    "                start_date, end_date = args\n",
    "                url, params = self._wx_get_api_url(start_date, end_date)\n",
    "                responses = self.openmeteo.weather_api(url, params=params)\n",
    "                response = responses[0]\n",
    "                \n",
    "                hourly = response.Hourly()\n",
    "                hourly_data = {\n",
    "                    \"date\": pd.date_range(\n",
    "                        start=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True),\n",
    "                        end=pd.to_datetime(hourly.TimeEnd(), unit=\"s\", utc=True),\n",
    "                        freq=pd.Timedelta(seconds=hourly.Interval()), inclusive=\"left\"\n",
    "                    ),\n",
    "                    \"temperature_2m\": hourly.Variables(0).ValuesAsNumpy(),\n",
    "                    \"weather_code\": hourly.Variables(1).ValuesAsNumpy(),\n",
    "                    \"relative_humidity_2m\": hourly.Variables(2).ValuesAsNumpy(),\n",
    "                    \"wind_speed_10m\": hourly.Variables(3).ValuesAsNumpy()\n",
    "                }\n",
    "                \n",
    "                df = pd.DataFrame(data=hourly_data)\n",
    "                create_directories([self.config.wx_raw_data])\n",
    "                file_path = self.config.wx_raw_data / f\"weather_data_{start_date.strftime('%Y-%m-%d')}_to_{end_date.strftime('%Y-%m-%d')}.csv\"\n",
    "                df.to_csv(file_path, index=False)\n",
    "                return df\n",
    "                \n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching {data_type} data: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def _load_existing_data(self, data_type, *args):\n",
    "        \"\"\"Load existing data if files exist\"\"\"\n",
    "        try:\n",
    "            if data_type == \"electricity\":\n",
    "                year, month, day = args\n",
    "                file_path = self.config.elec_raw_data / f\"hourly_demand_{year}-{month:02d}-{day:02d}.json\"\n",
    "                if file_path.exists():\n",
    "                    data = load_json(file_path)\n",
    "                    if 'response' in data and 'data' in data['response']:\n",
    "                        return pd.DataFrame(data['response']['data'])\n",
    "                        \n",
    "            elif data_type == \"weather\":\n",
    "                start_date, end_date = args\n",
    "                file_path = self.config.wx_raw_data / f\"weather_data_{start_date.strftime('%Y-%m-%d')}_to_{end_date.strftime('%Y-%m-%d')}.csv\"\n",
    "                if file_path.exists():\n",
    "                    return pd.read_csv(file_path)\n",
    "                    \n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading {data_type} data: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def download(self) -> pd.DataFrame:\n",
    "        \"\"\"Download electricity and weather data, merge and save\"\"\"\n",
    "        try:\n",
    "            start = pd.to_datetime(self.config.start_date, utc=True)\n",
    "            end = pd.to_datetime(self.config.end_date, utc=True)\n",
    "            \n",
    "            # Get electricity data\n",
    "            elec_data = []\n",
    "            current_date = start\n",
    "            while current_date <= end:\n",
    "                year, month, day = current_date.year, current_date.month, current_date.day\n",
    "                \n",
    "                # Try loading existing data first\n",
    "                df = self._load_existing_data(\"electricity\", year, month, day)\n",
    "                if df.empty:\n",
    "                    df = self._fetch_data(\"electricity\", year, month, day)\n",
    "                \n",
    "                if not df.empty:\n",
    "                    elec_data.append(df)\n",
    "                current_date += timedelta(days=1)\n",
    "            \n",
    "            # Get weather data\n",
    "            wx_df = self._load_existing_data(\"weather\", start, end)\n",
    "            if wx_df.empty:\n",
    "                wx_df = self._fetch_data(\"weather\", start, end)\n",
    "            \n",
    "            # Combine and save\n",
    "            if elec_data:\n",
    "                elec_df = pd.concat(elec_data, ignore_index=True)\n",
    "                \n",
    "                if not wx_df.empty:\n",
    "                    # Simple merge on date\n",
    "                    if 'period' in elec_df.columns:\n",
    "                        elec_df['date'] = pd.to_datetime(elec_df['period'], utc=True)\n",
    "                    if 'date' in wx_df.columns:\n",
    "                        wx_df['date'] = pd.to_datetime(wx_df['date'], utc=True)\n",
    "                    \n",
    "                    combined_df = pd.merge(elec_df, wx_df, on=\"date\", how=\"inner\")\n",
    "                else:\n",
    "                    combined_df = elec_df\n",
    "                \n",
    "                # Save final data\n",
    "                create_directories([self.config.data_file.parent])\n",
    "                combined_df.to_csv(self.config.data_file, index=False)\n",
    "                logger.info(f\"Dataset saved to {self.config.data_file}, shape: {combined_df.shape}\")\n",
    "                return combined_df\n",
    "            \n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during download: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1153064b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-06 12:12:20,426: INFO: helpers: yaml file: config_file\\config.yaml loaded successfully]\n",
      "[2025-07-06 12:12:20,431: INFO: helpers: yaml file: config_file\\params.yaml loaded successfully]\n",
      "[2025-07-06 12:12:20,438: INFO: helpers: yaml file: config_file\\schema.yaml loaded successfully]\n",
      "[2025-07-06 12:12:20,442: INFO: helpers: created directory at: artifacts]\n",
      "[2025-07-06 12:12:20,444: INFO: helpers: created directory at: data_ingestion]\n",
      "[2025-07-06 12:12:22,338: INFO: helpers: created directory at: artifacts\\data_ingestion\\raw\\elec_data]\n",
      "[2025-07-06 12:12:22,359: INFO: helpers: json file saved at: artifacts\\data_ingestion\\raw\\elec_data\\hourly_demand_2025-01-01.json]\n",
      "[2025-07-06 12:12:24,638: INFO: helpers: created directory at: artifacts\\data_ingestion\\raw\\elec_data]\n",
      "[2025-07-06 12:12:24,638: INFO: helpers: json file saved at: artifacts\\data_ingestion\\raw\\elec_data\\hourly_demand_2025-01-02.json]\n",
      "[2025-07-06 12:12:26,589: INFO: helpers: created directory at: artifacts\\data_ingestion\\raw\\elec_data]\n",
      "[2025-07-06 12:12:26,605: INFO: helpers: json file saved at: artifacts\\data_ingestion\\raw\\elec_data\\hourly_demand_2025-01-03.json]\n",
      "[2025-07-06 12:12:28,475: INFO: helpers: created directory at: artifacts\\data_ingestion\\raw\\elec_data]\n",
      "[2025-07-06 12:12:28,475: INFO: helpers: json file saved at: artifacts\\data_ingestion\\raw\\elec_data\\hourly_demand_2025-01-04.json]\n",
      "[2025-07-06 12:12:30,509: INFO: helpers: created directory at: artifacts\\data_ingestion\\raw\\elec_data]\n",
      "[2025-07-06 12:12:30,513: INFO: helpers: json file saved at: artifacts\\data_ingestion\\raw\\elec_data\\hourly_demand_2025-01-05.json]\n",
      "[2025-07-06 12:12:32,390: INFO: helpers: created directory at: artifacts\\data_ingestion\\raw\\elec_data]\n",
      "[2025-07-06 12:12:32,395: INFO: helpers: json file saved at: artifacts\\data_ingestion\\raw\\elec_data\\hourly_demand_2025-01-06.json]\n",
      "[2025-07-06 12:12:34,495: INFO: helpers: created directory at: artifacts\\data_ingestion\\raw\\elec_data]\n",
      "[2025-07-06 12:12:34,505: INFO: helpers: json file saved at: artifacts\\data_ingestion\\raw\\elec_data\\hourly_demand_2025-01-07.json]\n",
      "[2025-07-06 12:12:36,404: INFO: helpers: created directory at: artifacts\\data_ingestion\\raw\\elec_data]\n",
      "[2025-07-06 12:12:36,411: INFO: helpers: json file saved at: artifacts\\data_ingestion\\raw\\elec_data\\hourly_demand_2025-01-08.json]\n",
      "[2025-07-06 12:12:38,472: INFO: helpers: created directory at: artifacts\\data_ingestion\\raw\\elec_data]\n",
      "[2025-07-06 12:12:38,488: INFO: helpers: json file saved at: artifacts\\data_ingestion\\raw\\elec_data\\hourly_demand_2025-01-09.json]\n",
      "[2025-07-06 12:12:40,371: INFO: helpers: created directory at: artifacts\\data_ingestion\\raw\\elec_data]\n",
      "[2025-07-06 12:12:40,372: INFO: helpers: json file saved at: artifacts\\data_ingestion\\raw\\elec_data\\hourly_demand_2025-01-10.json]\n",
      "[2025-07-06 12:12:40,394: INFO: helpers: created directory at: artifacts\\data_ingestion\\raw\\wx_data]\n",
      "[2025-07-06 12:12:40,445: INFO: helpers: created directory at: artifacts\\data_ingestion\\data]\n",
      "[2025-07-06 12:12:40,475: INFO: 581113550: Dataset saved to artifacts\\data_ingestion\\data\\elec_wx_demand.csv, shape: (2706, 12)]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    ingestion_config = config.get_data_ingestion_config()\n",
    "    ingestion = DataIngestion(config=ingestion_config)\n",
    "    df = ingestion.download()\n",
    "\n",
    "except Exception as e:\n",
    "    raise CustomException(str(e), sys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WattPredictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
